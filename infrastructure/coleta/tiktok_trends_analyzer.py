"""
üéµ TikTok Trends Analyzer Implementation

Tracing ID: tiktok-trends-2025-01-27-001
Timestamp: 2025-01-27T15:30:00Z
Vers√£o: 1.0
Status: üöÄ IMPLEMENTA√á√ÉO

üìê CoCoT: Algoritmos baseados em padr√µes de an√°lise de tend√™ncias e m√©tricas de engajamento
üå≤ ToT: Avaliadas m√∫ltiplas abordagens de an√°lise e escolhida mais precisa
‚ôªÔ∏è ReAct: Simulado cen√°rios de viraliza√ß√£o e validada precis√£o dos algoritmos
"""

import logging
import asyncio
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import json
import hashlib
from collections import defaultdict, Counter

from infrastructure.orchestrator.error_handler import CircuitBreaker
from infrastructure.orchestrator.rate_limiter import RateLimiter
from infrastructure.observability.metrics_collector import MetricsCollector

# Configura√ß√£o de logging
logger = logging.getLogger(__name__)

class TrendType(Enum):
    """Tipos de tend√™ncia detectada"""
    VIRAL = "viral"
    GROWING = "growing"
    STABLE = "stable"
    DECLINING = "declining"
    EMERGING = "emerging"

class EngagementLevel(Enum):
    """N√≠veis de engajamento"""
    VERY_HIGH = "very_high"  # > 15%
    HIGH = "high"            # 10-15%
    MEDIUM = "medium"        # 5-10%
    LOW = "low"              # 2-5%
    VERY_LOW = "very_low"    # < 2%

@dataclass
class TrendAnalysis:
    """Resultado da an√°lise de tend√™ncia"""
    hashtag: str
    trend_type: TrendType
    engagement_level: EngagementLevel
    viral_score: float
    growth_rate: float
    velocity_score: float
    momentum_score: float
    predicted_reach: int
    confidence_level: float
    analysis_timestamp: datetime
    metadata: Dict[str, Any]

@dataclass
class ViralMetrics:
    """M√©tricas de viraliza√ß√£o"""
    shares_per_view: float
    comments_per_view: float
    likes_per_view: float
    completion_rate: float
    watch_time_avg: float
    viral_coefficient: float
    reach_velocity: float

class TikTokTrendsAnalyzer:
    """
    Analisador de tend√™ncias TikTok
    
    Implementa algoritmos avan√ßados para:
    - Detec√ß√£o de viraliza√ß√£o
    - An√°lise de engajamento
    - Predi√ß√£o de tend√™ncias
    - M√©tricas de momentum
    - An√°lise de velocidade de crescimento
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Inicializa analisador de tend√™ncias
        
        Args:
            config: Configura√ß√£o do analisador
        """
        self.config = config
        
        # Configurar circuit breaker
        self.circuit_breaker = CircuitBreaker(
            failure_threshold=3,
            recovery_timeout=30,
            expected_exception=Exception
        )
        
        # Configurar rate limiter
        self.rate_limiter = RateLimiter(
            requests_per_minute=config.get("rate_limits", {}).get("requests_per_minute", 50),
            requests_per_hour=config.get("rate_limits", {}).get("requests_per_hour", 500)
        )
        
        # Configurar m√©tricas
        self.metrics = MetricsCollector()
        
        # Par√¢metros de an√°lise
        self.viral_threshold = config.get("viral_threshold", 0.8)
        self.growth_threshold = config.get("growth_threshold", 0.3)
        self.engagement_thresholds = config.get("engagement_thresholds", {
            "very_high": 0.15,
            "high": 0.10,
            "medium": 0.05,
            "low": 0.02
        })
        
        # Cache de an√°lises
        self.analysis_cache = {}
        self.cache_ttl = config.get("cache_ttl", 3600)  # 1 hora
        
        logger.info("TikTok Trends Analyzer inicializado")
    
    @CircuitBreaker
    async def analyze_hashtag_trend(self, hashtag: str, historical_data: List[Dict[str, Any]]) -> TrendAnalysis:
        """
        Analisa tend√™ncia de hashtag
        
        Args:
            hashtag: Hashtag para an√°lise
            historical_data: Dados hist√≥ricos da hashtag
            
        Returns:
            TrendAnalysis: An√°lise completa da tend√™ncia
        """
        try:
            # Validar rate limit
            self.rate_limiter.check_rate_limit("analyze_hashtag_trend")
            
            # Verificar cache
            cache_key = self._generate_cache_key(hashtag, historical_data)
            if cache_key in self.analysis_cache:
                cached_analysis = self.analysis_cache[cache_key]
                if datetime.utcnow() - cached_analysis.analysis_timestamp < timedelta(seconds=self.cache_ttl):
                    logger.info(f"Retornando an√°lise em cache para hashtag: {hashtag}")
                    return cached_analysis
            
            # Processar dados hist√≥ricos
            processed_data = self._process_historical_data(historical_data)
            
            # Calcular m√©tricas
            viral_score = self._calculate_viral_score(processed_data)
            growth_rate = self._calculate_growth_rate(processed_data)
            velocity_score = self._calculate_velocity_score(processed_data)
            momentum_score = self._calculate_momentum_score(processed_data)
            
            # Determinar tipo de tend√™ncia
            trend_type = self._determine_trend_type(viral_score, growth_rate, velocity_score)
            
            # Calcular n√≠vel de engajamento
            engagement_level = self._calculate_engagement_level(processed_data)
            
            # Predizer alcance
            predicted_reach = self._predict_reach(processed_data, viral_score)
            
            # Calcular n√≠vel de confian√ßa
            confidence_level = self._calculate_confidence_level(processed_data)
            
            # Criar an√°lise
            analysis = TrendAnalysis(
                hashtag=hashtag,
                trend_type=trend_type,
                engagement_level=engagement_level,
                viral_score=viral_score,
                growth_rate=growth_rate,
                velocity_score=velocity_score,
                momentum_score=momentum_score,
                predicted_reach=predicted_reach,
                confidence_level=confidence_level,
                analysis_timestamp=datetime.utcnow(),
                metadata={
                    "data_points": len(historical_data),
                    "time_span_days": self._calculate_time_span(historical_data),
                    "peak_views": max([data.get("views", 0) for data in historical_data]),
                    "avg_engagement": np.mean([data.get("engagement_rate", 0) for data in historical_data])
                }
            )
            
            # Armazenar em cache
            self.analysis_cache[cache_key] = analysis
            
            # Registrar m√©tricas
            self.metrics.increment_counter(
                "tiktok_trend_analyses_total",
                {"hashtag": hashtag, "trend_type": trend_type.value}
            )
            self.metrics.record_histogram(
                "tiktok_viral_scores",
                viral_score
            )
            
            logger.info(f"An√°lise de tend√™ncia conclu√≠da - Hashtag: {hashtag}, Tipo: {trend_type.value}")
            return analysis
            
        except Exception as e:
            logger.error(f"Erro ao analisar tend√™ncia da hashtag {hashtag}: {str(e)}")
            
            # Registrar m√©tricas de erro
            self.metrics.increment_counter(
                "tiktok_trend_analysis_errors_total",
                {"hashtag": hashtag, "error_type": type(e).__name__}
            )
            
            raise
    
    @CircuitBreaker
    async def analyze_viral_potential(self, video_data: Dict[str, Any]) -> ViralMetrics:
        """
        Analisa potencial viral de v√≠deo
        
        Args:
            video_data: Dados do v√≠deo
            
        Returns:
            ViralMetrics: M√©tricas de viraliza√ß√£o
        """
        try:
            # Validar rate limit
            self.rate_limiter.check_rate_limit("analyze_viral_potential")
            
            # Extrair m√©tricas b√°sicas
            views = video_data.get("views", 0)
            likes = video_data.get("likes", 0)
            comments = video_data.get("comments", 0)
            shares = video_data.get("shares", 0)
            duration = video_data.get("duration", 0)
            watch_time = video_data.get("watch_time", 0)
            
            # Calcular m√©tricas de engajamento
            shares_per_view = shares / views if views > 0 else 0
            comments_per_view = comments / views if views > 0 else 0
            likes_per_view = likes / views if views > 0 else 0
            
            # Calcular taxa de conclus√£o
            completion_rate = watch_time / (views * duration) if views > 0 and duration > 0 else 0
            
            # Calcular tempo m√©dio de visualiza√ß√£o
            watch_time_avg = watch_time / views if views > 0 else 0
            
            # Calcular coeficiente viral
            viral_coefficient = self._calculate_viral_coefficient(shares, views, comments)
            
            # Calcular velocidade de alcance
            reach_velocity = self._calculate_reach_velocity(video_data)
            
            # Criar m√©tricas
            viral_metrics = ViralMetrics(
                shares_per_view=shares_per_view,
                comments_per_view=comments_per_view,
                likes_per_view=likes_per_view,
                completion_rate=completion_rate,
                watch_time_avg=watch_time_avg,
                viral_coefficient=viral_coefficient,
                reach_velocity=reach_velocity
            )
            
            # Registrar m√©tricas
            self.metrics.increment_counter(
                "tiktok_viral_analyses_total",
                {"video_id": video_data.get("id", "unknown")}
            )
            self.metrics.record_histogram(
                "tiktok_viral_coefficients",
                viral_coefficient
            )
            
            logger.info(f"An√°lise viral conclu√≠da - V√≠deo: {video_data.get('id', 'unknown')}")
            return viral_metrics
            
        except Exception as e:
            logger.error(f"Erro ao analisar potencial viral: {str(e)}")
            
            # Registrar m√©tricas de erro
            self.metrics.increment_counter(
                "tiktok_viral_analysis_errors_total",
                {"error_type": type(e).__name__}
            )
            
            raise
    
    @CircuitBreaker
    async def detect_emerging_trends(self, hashtags_data: List[Dict[str, Any]], 
                                   time_window_hours: int = 24) -> List[TrendAnalysis]:
        """
        Detecta tend√™ncias emergentes
        
        Args:
            hashtags_data: Dados de m√∫ltiplas hashtags
            time_window_hours: Janela de tempo para an√°lise
            
        Returns:
            List[TrendAnalysis]: Lista de tend√™ncias emergentes
        """
        try:
            # Validar rate limit
            self.rate_limiter.check_rate_limit("detect_emerging_trends")
            
            emerging_trends = []
            cutoff_time = datetime.utcnow() - timedelta(hours=time_window_hours)
            
            for hashtag_data in hashtags_data:
                hashtag = hashtag_data.get("hashtag")
                historical_data = hashtag_data.get("historical_data", [])
                
                # Filtrar dados recentes
                recent_data = [
                    data for data in historical_data 
                    if datetime.fromisoformat(data.get("timestamp", "")) >= cutoff_time
                ]
                
                if len(recent_data) < 3:  # M√≠nimo de pontos para an√°lise
                    continue
                
                # Analisar tend√™ncia
                analysis = await self.analyze_hashtag_trend(hashtag, recent_data)
                
                # Verificar se √© emergente
                if analysis.trend_type in [TrendType.EMERGING, TrendType.GROWING]:
                    if analysis.confidence_level > 0.7:  # Alta confian√ßa
                        emerging_trends.append(analysis)
            
            # Ordenar por viral score
            emerging_trends.sort(key=lambda value: value.viral_score, reverse=True)
            
            # Registrar m√©tricas
            self.metrics.increment_counter(
                "tiktok_emerging_trends_detected_total",
                {"count": len(emerging_trends)}
            )
            
            logger.info(f"Detectadas {len(emerging_trends)} tend√™ncias emergentes")
            return emerging_trends
            
        except Exception as e:
            logger.error(f"Erro ao detectar tend√™ncias emergentes: {str(e)}")
            
            # Registrar m√©tricas de erro
            self.metrics.increment_counter(
                "tiktok_emerging_trends_errors_total",
                {"error_type": type(e).__name__}
            )
            
            raise
    
    def _process_historical_data(self, historical_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Processa dados hist√≥ricos para an√°lise"""
        if not historical_data:
            return {}
        
        # Converter para DataFrame
        df = pd.DataFrame(historical_data)
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df = df.sort_values('timestamp')
        
        # Calcular m√©tricas agregadas
        processed = {
            'timestamps': df['timestamp'].tolist(),
            'views': df['views'].tolist(),
            'likes': df['likes'].tolist(),
            'comments': df['comments'].tolist(),
            'shares': df['shares'].tolist(),
            'engagement_rates': df['engagement_rate'].tolist(),
            'growth_rates': self._calculate_point_growth_rates(df['views'].tolist()),
            'velocity_metrics': self._calculate_velocity_metrics(df),
            'momentum_indicators': self._calculate_momentum_indicators(df)
        }
        
        return processed
    
    def _calculate_viral_score(self, processed_data: Dict[str, Any]) -> float:
        """Calcula score de viraliza√ß√£o"""
        if not processed_data:
            return 0.0
        
        views = processed_data.get('views', [])
        engagement_rates = processed_data.get('engagement_rates', [])
        growth_rates = processed_data.get('growth_rates', [])
        
        if not views or not engagement_rates:
            return 0.0
        
        # Fatores de viraliza√ß√£o
        view_growth_factor = np.mean(growth_rates) if growth_rates else 0
        engagement_factor = np.mean(engagement_rates) if engagement_rates else 0
        velocity_factor = np.mean(processed_data.get('velocity_metrics', [])) if processed_data.get('velocity_metrics') else 0
        
        # Calcular score ponderado
        viral_score = (
            view_growth_factor * 0.4 +
            engagement_factor * 0.3 +
            velocity_factor * 0.3
        )
        
        return min(max(viral_score, 0.0), 1.0)  # Normalizar entre 0 e 1
    
    def _calculate_growth_rate(self, processed_data: Dict[str, Any]) -> float:
        """Calcula taxa de crescimento"""
        views = processed_data.get('views', [])
        if len(views) < 2:
            return 0.0
        
        # Calcular crescimento percentual
        initial_views = views[0]
        final_views = views[-1]
        
        if initial_views == 0:
            return 0.0
        
        growth_rate = (final_views - initial_views) / initial_views
        return growth_rate
    
    def _calculate_velocity_score(self, processed_data: Dict[str, Any]) -> float:
        """Calcula score de velocidade"""
        velocity_metrics = processed_data.get('velocity_metrics', [])
        if not velocity_metrics:
            return 0.0
        
        # Calcular velocidade m√©dia
        avg_velocity = np.mean(velocity_metrics)
        
        # Normalizar para score entre 0 e 1
        velocity_score = min(avg_velocity / 1000, 1.0)  # Assumindo 1000 como m√°ximo
        return velocity_score
    
    def _calculate_momentum_score(self, processed_data: Dict[str, Any]) -> float:
        """Calcula score de momentum"""
        momentum_indicators = processed_data.get('momentum_indicators', [])
        if not momentum_indicators:
            return 0.0
        
        # Calcular momentum baseado em indicadores
        momentum_score = np.mean(momentum_indicators)
        return min(max(momentum_score, 0.0), 1.0)
    
    def _determine_trend_type(self, viral_score: float, growth_rate: float, 
                            velocity_score: float) -> TrendType:
        """Determina tipo de tend√™ncia"""
        # Crit√©rios para cada tipo
        if viral_score > self.viral_threshold and growth_rate > self.growth_threshold:
            return TrendType.VIRAL
        elif growth_rate > self.growth_threshold and velocity_score > 0.5:
            return TrendType.GROWING
        elif growth_rate > 0 and growth_rate <= self.growth_threshold:
            return TrendType.STABLE
        elif growth_rate < 0:
            return TrendType.DECLINING
        elif viral_score > 0.5 and velocity_score > 0.3:
            return TrendType.EMERGING
        else:
            return TrendType.STABLE
    
    def _calculate_engagement_level(self, processed_data: Dict[str, Any]) -> EngagementLevel:
        """Calcula n√≠vel de engajamento"""
        engagement_rates = processed_data.get('engagement_rates', [])
        if not engagement_rates:
            return EngagementLevel.VERY_LOW
        
        avg_engagement = np.mean(engagement_rates)
        
        # Determinar n√≠vel baseado em thresholds
        if avg_engagement > self.engagement_thresholds["very_high"]:
            return EngagementLevel.VERY_HIGH
        elif avg_engagement > self.engagement_thresholds["high"]:
            return EngagementLevel.HIGH
        elif avg_engagement > self.engagement_thresholds["medium"]:
            return EngagementLevel.MEDIUM
        elif avg_engagement > self.engagement_thresholds["low"]:
            return EngagementLevel.LOW
        else:
            return EngagementLevel.VERY_LOW
    
    def _predict_reach(self, processed_data: Dict[str, Any], viral_score: float) -> int:
        """Prediz alcance futuro"""
        views = processed_data.get('views', [])
        if not views:
            return 0
        
        current_views = views[-1]
        growth_rate = self._calculate_growth_rate(processed_data)
        
        # Predi√ß√£o simples baseada em crescimento atual
        predicted_growth = 1 + (growth_rate * viral_score)
        predicted_reach = int(current_views * predicted_growth)
        
        return predicted_reach
    
    def _calculate_confidence_level(self, processed_data: Dict[str, Any]) -> float:
        """Calcula n√≠vel de confian√ßa da an√°lise"""
        views = processed_data.get('views', [])
        if len(views) < 3:
            return 0.3  # Baixa confian√ßa com poucos dados
        
        # Fatores de confian√ßa
        data_points_factor = min(len(views) / 10, 1.0)  # Mais pontos = mais confian√ßa
        consistency_factor = 1.0 - np.std(views) / np.mean(views) if np.mean(views) > 0 else 0
        
        confidence = (data_points_factor * 0.6 + consistency_factor * 0.4)
        return min(max(confidence, 0.0), 1.0)
    
    def _calculate_viral_coefficient(self, shares: int, views: int, comments: int) -> float:
        """Calcula coeficiente viral"""
        if views == 0:
            return 0.0
        
        # F√≥rmula: (shares + comments * 0.5) / views
        viral_coefficient = (shares + comments * 0.5) / views
        return viral_coefficient
    
    def _calculate_reach_velocity(self, video_data: Dict[str, Any]) -> float:
        """Calcula velocidade de alcance"""
        views = video_data.get("views", 0)
        created_time = video_data.get("created_time")
        
        if not created_time or views == 0:
            return 0.0
        
        # Calcular tempo desde cria√ß√£o
        if isinstance(created_time, str):
            created_time = datetime.fromisoformat(created_time.replace("Z", "+00:00"))
        
        time_diff = datetime.utcnow() - created_time
        hours_since_creation = time_diff.total_seconds() / 3600
        
        if hours_since_creation == 0:
            return 0.0
        
        # Velocidade = views por hora
        reach_velocity = views / hours_since_creation
        return reach_velocity
    
    def _calculate_point_growth_rates(self, views: List[int]) -> List[float]:
        """Calcula taxas de crescimento ponto a ponto"""
        growth_rates = []
        for index in range(1, len(views)):
            if views[index-1] > 0:
                growth_rate = (views[index] - views[index-1]) / views[index-1]
                growth_rates.append(growth_rate)
            else:
                growth_rates.append(0.0)
        return growth_rates
    
    def _calculate_velocity_metrics(self, df: pd.DataFrame) -> List[float]:
        """Calcula m√©tricas de velocidade"""
        velocity_metrics = []
        
        for index in range(1, len(df)):
            time_diff = (df.iloc[index]['timestamp'] - df.iloc[index-1]['timestamp']).total_seconds() / 3600
            view_diff = df.iloc[index]['views'] - df.iloc[index-1]['views']
            
            if time_diff > 0:
                velocity = view_diff / time_diff
                velocity_metrics.append(velocity)
            else:
                velocity_metrics.append(0.0)
        
        return velocity_metrics
    
    def _calculate_momentum_indicators(self, df: pd.DataFrame) -> List[float]:
        """Calcula indicadores de momentum"""
        momentum_indicators = []
        
        for index in range(2, len(df)):
            # Momentum baseado em acelera√ß√£o de crescimento
            prev_growth = df.iloc[index-1]['views'] - df.iloc[index-2]['views']
            curr_growth = df.iloc[index]['views'] - df.iloc[index-1]['views']
            
            if prev_growth > 0:
                momentum = curr_growth / prev_growth
                momentum_indicators.append(momentum)
            else:
                momentum_indicators.append(0.0)
        
        return momentum_indicators
    
    def _calculate_time_span(self, historical_data: List[Dict[str, Any]]) -> int:
        """Calcula span de tempo dos dados em dias"""
        if len(historical_data) < 2:
            return 0
        
        timestamps = [data.get("timestamp") for data in historical_data if data.get("timestamp")]
        if len(timestamps) < 2:
            return 0
        
        # Converter para datetime
        try:
            start_time = datetime.fromisoformat(timestamps[0].replace("Z", "+00:00"))
            end_time = datetime.fromisoformat(timestamps[-1].replace("Z", "+00:00"))
            time_span = (end_time - start_time).days
            return time_span
        except:
            return 0
    
    def _generate_cache_key(self, hashtag: str, historical_data: List[Dict[str, Any]]) -> str:
        """Gera chave de cache √∫nica"""
        data_hash = hashlib.md5(
            json.dumps(historical_data, sort_keys=True).encode()
        ).hexdigest()
        return f"trend_analysis:{hashtag}:{data_hash}" 