#!/usr/bin/env python3
"""
üéØ Sistema de Otimiza√ß√£o de Performance - IMP-016
=================================================

Tracing ID: PERFORMANCE_OPTIMIZER_IMP016_20250127_001
Data: 2025-01-27
Vers√£o: 1.0.0

Sistema avan√ßado de otimiza√ß√£o de performance que:
- Otimiza queries de banco de dados
- Implementa cache inteligente
- Monitora m√©tricas de performance
- Aplica otimiza√ß√µes autom√°ticas
- Fornece relat√≥rios detalhados
- Integra com observabilidade

Prompt: CHECKLIST_CONFIABILIDADE.md - IMP-016
Ruleset: enterprise_control_layer.yaml
"""

import time
import json
import logging
import asyncio
from typing import Dict, List, Any, Optional, Tuple, Callable, Union
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict, deque
import statistics
import psutil
import gc
from functools import wraps, lru_cache
import threading
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

# Cache e otimiza√ß√£o
import redis
from cachetools import TTLCache, LRUCache
import numpy as np

# Logging estruturado
from shared.logger import logger

# Observabilidade
from infrastructure.observability.metrics import MetricsCollector
from infrastructure.observability.tracing import trace_function


class OptimizationType(Enum):
    """Tipos de otimiza√ß√£o dispon√≠veis."""
    CACHE = "cache"
    QUERY = "query"
    MEMORY = "memory"
    CPU = "cpu"
    NETWORK = "network"
    DATABASE = "database"
    CONCURRENCY = "concurrency"


class PerformanceMetric(Enum):
    """M√©tricas de performance monitoradas."""
    RESPONSE_TIME = "response_time"
    THROUGHPUT = "throughput"
    MEMORY_USAGE = "memory_usage"
    CPU_USAGE = "cpu_usage"
    CACHE_HIT_RATE = "cache_hit_rate"
    QUERY_TIME = "query_time"
    ERROR_RATE = "error_rate"


@dataclass
class OptimizationConfig:
    """Configura√ß√£o para otimiza√ß√£o de performance."""
    cache_ttl: int = 3600
    cache_max_size: int = 1000
    query_timeout: int = 30
    max_concurrent_queries: int = 10
    memory_threshold: float = 0.8
    cpu_threshold: float = 0.7
    enable_auto_optimization: bool = True
    optimization_interval: int = 300
    metrics_collection_interval: int = 60


@dataclass
class PerformanceMetrics:
    """M√©tricas de performance coletadas."""
    response_time: float = 0.0
    throughput: float = 0.0
    memory_usage: float = 0.0
    cpu_usage: float = 0.0
    cache_hit_rate: float = 0.0
    query_time: float = 0.0
    error_rate: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class OptimizationResult:
    """Resultado de uma otimiza√ß√£o."""
    optimization_type: OptimizationType
    success: bool
    improvement_percentage: float
    details: Dict[str, Any]
    timestamp: datetime = field(default_factory=datetime.now)
    duration: float = 0.0


class PerformanceOptimizer:
    """
    Sistema principal de otimiza√ß√£o de performance.
    
    Respons√°vel por:
    - Monitorar m√©tricas de performance
    - Aplicar otimiza√ß√µes autom√°ticas
    - Gerenciar cache inteligente
    - Otimizar queries
    - Fornecer relat√≥rios
    """
    
    def __init__(self, config: OptimizationConfig):
        self.config = config
        self.metrics_collector = MetricsCollector()
        self.cache = TTLCache(maxsize=config.cache_max_size, ttl=config.cache_ttl)
        self.performance_history = deque(maxlen=1000)
        self.optimization_history = deque(maxlen=100)
        self.monitoring_active = False
        self.optimization_thread = None
        self.metrics_thread = None
        
        # Inicializar m√©tricas
        self.current_metrics = PerformanceMetrics()
        self.baseline_metrics = None
        
        logger.info(f"PerformanceOptimizer inicializado com config: {config}")
    
    @trace_function(operation_name="start_monitoring", service_name="performance-optimizer")
    def start_monitoring(self) -> bool:
        """Inicia o monitoramento de performance."""
        try:
            if self.monitoring_active:
                logger.warning("Monitoramento j√° est√° ativo")
                return True
            
            self.monitoring_active = True
            
            # Iniciar thread de coleta de m√©tricas
            self.metrics_thread = threading.Thread(
                target=self._metrics_collection_loop,
                daemon=True
            )
            self.metrics_thread.start()
            
            # Iniciar thread de otimiza√ß√£o autom√°tica
            if self.config.enable_auto_optimization:
                self.optimization_thread = threading.Thread(
                    target=self._auto_optimization_loop,
                    daemon=True
                )
                self.optimization_thread.start()
            
            # Estabelecer baseline
            self._establish_baseline()
            
            logger.info("Monitoramento de performance iniciado com sucesso")
            return True
            
        except Exception as e:
            logger.error(f"Erro ao iniciar monitoramento: {str(e)}")
            return False
    
    @trace_function(operation_name="stop_monitoring", service_name="performance-optimizer")
    def stop_monitoring(self) -> bool:
        """Para o monitoramento de performance."""
        try:
            self.monitoring_active = False
            
            if self.metrics_thread:
                self.metrics_thread.join(timeout=5)
            
            if self.optimization_thread:
                self.optimization_thread.join(timeout=5)
            
            logger.info("Monitoramento de performance parado")
            return True
            
        except Exception as e:
            logger.error(f"Erro ao parar monitoramento: {str(e)}")
            return False
    
    @trace_function(operation_name="collect_metrics", service_name="performance-optimizer")
    def collect_metrics(self) -> PerformanceMetrics:
        """Coleta m√©tricas atuais de performance."""
        try:
            # M√©tricas do sistema
            memory = psutil.virtual_memory()
            cpu = psutil.cpu_percent(interval=1)
            
            # M√©tricas de cache
            cache_hit_rate = self._calculate_cache_hit_rate()
            
            # M√©tricas de queries (simuladas)
            query_time = self._get_average_query_time()
            
            # M√©tricas de throughput (simuladas)
            throughput = self._calculate_throughput()
            
            # M√©tricas de erro (simuladas)
            error_rate = self._calculate_error_rate()
            
            metrics = PerformanceMetrics(
                memory_usage=memory.percent / 100.0,
                cpu_usage=cpu / 100.0,
                cache_hit_rate=cache_hit_rate,
                query_time=query_time,
                throughput=throughput,
                error_rate=error_rate,
                timestamp=datetime.now()
            )
            
            self.current_metrics = metrics
            self.performance_history.append(metrics)
            
            # Enviar para observabilidade
            self._send_metrics_to_observability(metrics)
            
            return metrics
            
        except Exception as e:
            logger.error(f"Erro ao coletar m√©tricas: {str(e)}")
            return PerformanceMetrics()
    
    @trace_function(operation_name="optimize_cache", service_name="performance-optimizer")
    def optimize_cache(self) -> OptimizationResult:
        """Otimiza o cache baseado em padr√µes de uso."""
        try:
            start_time = time.time()
            
            # Analisar padr√µes de cache
            cache_stats = self._analyze_cache_patterns()
            
            # Aplicar otimiza√ß√µes
            optimizations = []
            
            # Limpar cache expirado
            if cache_stats['expired_entries'] > 0:
                self._clean_expired_cache()
                optimizations.append("cache_cleanup")
            
            # Ajustar TTL baseado em padr√µes
            if cache_stats['hit_rate'] < 0.7:
                new_ttl = self._calculate_optimal_ttl()
                self.config.cache_ttl = new_ttl
                optimizations.append("ttl_adjustment")
            
            # Pr√©-carregar dados frequentes
            if cache_stats['frequent_keys']:
                self._preload_frequent_data(cache_stats['frequent_keys'])
                optimizations.append("preload_frequent")
            
            duration = time.time() - start_time
            
            result = OptimizationResult(
                optimization_type=OptimizationType.CACHE,
                success=True,
                improvement_percentage=self._calculate_cache_improvement(),
                details={
                    'optimizations_applied': optimizations,
                    'cache_stats': cache_stats,
                    'new_ttl': self.config.cache_ttl
                },
                duration=duration
            )
            
            self.optimization_history.append(result)
            logger.info(f"Otimiza√ß√£o de cache conclu√≠da: {result}")
            
            return result
            
        except Exception as e:
            logger.error(f"Erro na otimiza√ß√£o de cache: {str(e)}")
            return OptimizationResult(
                optimization_type=OptimizationType.CACHE,
                success=False,
                improvement_percentage=0.0,
                details={'error': str(e)}
            )
    
    @trace_function(operation_name="optimize_queries", service_name="performance-optimizer")
    def optimize_queries(self) -> OptimizationResult:
        """Otimiza queries de banco de dados."""
        try:
            start_time = time.time()
            
            # Analisar queries lentas
            slow_queries = self._identify_slow_queries()
            
            # Aplicar otimiza√ß√µes
            optimizations = []
            
            for query in slow_queries:
                # Sugerir √≠ndices
                suggested_indexes = self._suggest_indexes(query)
                if suggested_indexes:
                    optimizations.append({
                        'type': 'index_suggestion',
                        'query': query['sql'],
                        'indexes': suggested_indexes
                    })
                
                # Otimizar estrutura da query
                optimized_query = self._optimize_query_structure(query)
                if optimized_query:
                    optimizations.append({
                        'type': 'query_optimization',
                        'original': query['sql'],
                        'optimized': optimized_query
                    })
            
            duration = time.time() - start_time
            
            result = OptimizationResult(
                optimization_type=OptimizationType.QUERY,
                success=True,
                improvement_percentage=self._calculate_query_improvement(),
                details={
                    'slow_queries_found': len(slow_queries),
                    'optimizations_applied': optimizations
                },
                duration=duration
            )
            
            self.optimization_history.append(result)
            logger.info(f"Otimiza√ß√£o de queries conclu√≠da: {result}")
            
            return result
            
        except Exception as e:
            logger.error(f"Erro na otimiza√ß√£o de queries: {str(e)}")
            return OptimizationResult(
                optimization_type=OptimizationType.QUERY,
                success=False,
                improvement_percentage=0.0,
                details={'error': str(e)}
            )
    
    @trace_function(operation_name="optimize_memory", service_name="performance-optimizer")
    def optimize_memory(self) -> OptimizationResult:
        """Otimiza uso de mem√≥ria."""
        try:
            start_time = time.time()
            
            # Analisar uso de mem√≥ria
            memory_usage = psutil.virtual_memory()
            
            optimizations = []
            
            # For√ßar garbage collection se necess√°rio
            if memory_usage.percent > 80:
                collected = gc.collect()
                optimizations.append(f"gc_collected_{collected}_objects")
            
            # Limpar cache se mem√≥ria alta
            if memory_usage.percent > 85:
                self._reduce_cache_size()
                optimizations.append("cache_size_reduction")
            
            # Otimizar estruturas de dados
            if memory_usage.percent > 70:
                self._optimize_data_structures()
                optimizations.append("data_structure_optimization")
            
            duration = time.time() - start_time
            
            result = OptimizationResult(
                optimization_type=OptimizationType.MEMORY,
                success=True,
                improvement_percentage=self._calculate_memory_improvement(),
                details={
                    'memory_usage_before': memory_usage.percent,
                    'memory_usage_after': psutil.virtual_memory().percent,
                    'optimizations_applied': optimizations
                },
                duration=duration
            )
            
            self.optimization_history.append(result)
            logger.info(f"Otimiza√ß√£o de mem√≥ria conclu√≠da: {result}")
            
            return result
            
        except Exception as e:
            logger.error(f"Erro na otimiza√ß√£o de mem√≥ria: {str(e)}")
            return OptimizationResult(
                optimization_type=OptimizationType.MEMORY,
                success=False,
                improvement_percentage=0.0,
                details={'error': str(e)}
            )
    
    @trace_function(operation_name="generate_performance_report", service_name="performance-optimizer")
    def generate_performance_report(self) -> Dict[str, Any]:
        """Gera relat√≥rio detalhado de performance."""
        try:
            if not self.performance_history:
                return {"error": "Nenhuma m√©trica coletada ainda"}
            
            # M√©tricas atuais
            current = self.current_metrics
            
            # M√©tricas hist√≥ricas
            history = list(self.performance_history)
            
            # Estat√≠sticas
            response_times = [m.response_time for m in history]
            memory_usage = [m.memory_usage for m in history]
            cpu_usage = [m.cpu_usage for m in history]
            cache_hit_rates = [m.cache_hit_rate for m in history]
            
            # Otimiza√ß√µes aplicadas
            optimizations = list(self.optimization_history)
            
            report = {
                "timestamp": datetime.now().isoformat(),
                "current_metrics": {
                    "response_time": current.response_time,
                    "throughput": current.throughput,
                    "memory_usage": current.memory_usage,
                    "cpu_usage": current.cpu_usage,
                    "cache_hit_rate": current.cache_hit_rate,
                    "query_time": current.query_time,
                    "error_rate": current.error_rate
                },
                "historical_stats": {
                    "response_time": {
                        "mean": statistics.mean(response_times) if response_times else 0,
                        "median": statistics.median(response_times) if response_times else 0,
                        "min": min(response_times) if response_times else 0,
                        "max": max(response_times) if response_times else 0
                    },
                    "memory_usage": {
                        "mean": statistics.mean(memory_usage) if memory_usage else 0,
                        "max": max(memory_usage) if memory_usage else 0
                    },
                    "cpu_usage": {
                        "mean": statistics.mean(cpu_usage) if cpu_usage else 0,
                        "max": max(cpu_usage) if cpu_usage else 0
                    },
                    "cache_hit_rate": {
                        "mean": statistics.mean(cache_hit_rates) if cache_hit_rates else 0,
                        "min": min(cache_hit_rates) if cache_hit_rates else 0
                    }
                },
                "optimizations": {
                    "total_applied": len(optimizations),
                    "successful": len([o for o in optimizations if o.success]),
                    "failed": len([o for o in optimizations if not o.success]),
                    "total_improvement": sum([o.improvement_percentage for o in optimizations if o.success]),
                    "recent_optimizations": [
                        {
                            "type": o.optimization_type.value,
                            "success": o.success,
                            "improvement": o.improvement_percentage,
                            "timestamp": o.timestamp.isoformat()
                        }
                        for o in optimizations[-10:]  # √öltimas 10 otimiza√ß√µes
                    ]
                },
                "recommendations": self._generate_recommendations()
            }
            
            logger.info(f"Relat√≥rio de performance gerado: {len(report)} se√ß√µes")
            return report
            
        except Exception as e:
            logger.error(f"Erro ao gerar relat√≥rio: {str(e)}")
            return {"error": str(e)}
    
    def _metrics_collection_loop(self):
        """Loop de coleta de m√©tricas."""
        while self.monitoring_active:
            try:
                self.collect_metrics()
                time.sleep(self.config.metrics_collection_interval)
            except Exception as e:
                logger.error(f"Erro no loop de m√©tricas: {str(e)}")
                time.sleep(10)
    
    def _auto_optimization_loop(self):
        """Loop de otimiza√ß√£o autom√°tica."""
        while self.monitoring_active:
            try:
                # Verificar se otimiza√ß√£o √© necess√°ria
                if self._should_optimize():
                    self._apply_auto_optimizations()
                
                time.sleep(self.config.optimization_interval)
            except Exception as e:
                logger.error(f"Erro no loop de otimiza√ß√£o: {str(e)}")
                time.sleep(60)
    
    def _establish_baseline(self):
        """Estabelece baseline de performance."""
        try:
            # Coletar m√©tricas por 5 minutos
            baseline_metrics = []
            for _ in range(5):
                metrics = self.collect_metrics()
                baseline_metrics.append(metrics)
                time.sleep(60)
            
            # Calcular m√©dias
            self.baseline_metrics = PerformanceMetrics(
                response_time=statistics.mean([m.response_time for m in baseline_metrics]),
                throughput=statistics.mean([m.throughput for m in baseline_metrics]),
                memory_usage=statistics.mean([m.memory_usage for m in baseline_metrics]),
                cpu_usage=statistics.mean([m.cpu_usage for m in baseline_metrics]),
                cache_hit_rate=statistics.mean([m.cache_hit_rate for m in baseline_metrics]),
                query_time=statistics.mean([m.query_time for m in baseline_metrics]),
                error_rate=statistics.mean([m.error_rate for m in baseline_metrics])
            )
            
            logger.info(f"Baseline estabelecido: {self.baseline_metrics}")
            
        except Exception as e:
            logger.error(f"Erro ao estabelecer baseline: {str(e)}")
    
    def _should_optimize(self) -> bool:
        """Verifica se otimiza√ß√£o √© necess√°ria."""
        if not self.baseline_metrics:
            return False
        
        # Verificar degrada√ß√£o de performance
        current = self.current_metrics
        
        # Se response time aumentou 20% ou mais
        if current.response_time > self.baseline_metrics.response_time * 1.2:
            return True
        
        # Se memory usage est√° acima do threshold
        if current.memory_usage > self.config.memory_threshold:
            return True
        
        # Se CPU usage est√° acima do threshold
        if current.cpu_usage > self.config.cpu_threshold:
            return True
        
        # Se cache hit rate caiu significativamente
        if current.cache_hit_rate < self.baseline_metrics.cache_hit_rate * 0.8:
            return True
        
        return False
    
    def _apply_auto_optimizations(self):
        """Aplica otimiza√ß√µes autom√°ticas."""
        try:
            logger.info("Aplicando otimiza√ß√µes autom√°ticas")
            
            # Otimizar cache
            self.optimize_cache()
            
            # Otimizar mem√≥ria se necess√°rio
            if self.current_metrics.memory_usage > self.config.memory_threshold:
                self.optimize_memory()
            
            # Otimizar queries se necess√°rio
            if self.current_metrics.query_time > self.baseline_metrics.query_time * 1.5:
                self.optimize_queries()
            
            logger.info("Otimiza√ß√µes autom√°ticas conclu√≠das")
            
        except Exception as e:
            logger.error(f"Erro nas otimiza√ß√µes autom√°ticas: {str(e)}")
    
    def _calculate_cache_hit_rate(self) -> float:
        """Calcula taxa de hit do cache."""
        # Simula√ß√£o - em produ√ß√£o seria baseado em m√©tricas reais
        return 0.85
    
    def _get_average_query_time(self) -> float:
        """Obt√©m tempo m√©dio de queries."""
        # Simula√ß√£o - em produ√ß√£o seria baseado em m√©tricas reais
        return 0.15
    
    def _calculate_throughput(self) -> float:
        """Calcula throughput atual."""
        # Simula√ß√£o - em produ√ß√£o seria baseado em m√©tricas reais
        return 150.0
    
    def _calculate_error_rate(self) -> float:
        """Calcula taxa de erro atual."""
        # Simula√ß√£o - em produ√ß√£o seria baseado em m√©tricas reais
        return 0.02
    
    def _send_metrics_to_observability(self, metrics: PerformanceMetrics):
        """Envia m√©tricas para sistema de observabilidade."""
        try:
            self.metrics_collector.record_metric("performance.response_time", metrics.response_time)
            self.metrics_collector.record_metric("performance.throughput", metrics.throughput)
            self.metrics_collector.record_metric("performance.memory_usage", metrics.memory_usage)
            self.metrics_collector.record_metric("performance.cpu_usage", metrics.cpu_usage)
            self.metrics_collector.record_metric("performance.cache_hit_rate", metrics.cache_hit_rate)
            self.metrics_collector.record_metric("performance.query_time", metrics.query_time)
            self.metrics_collector.record_metric("performance.error_rate", metrics.error_rate)
        except Exception as e:
            logger.error(f"Erro ao enviar m√©tricas: {str(e)}")
    
    def _analyze_cache_patterns(self) -> Dict[str, Any]:
        """Analisa padr√µes de uso do cache."""
        # Simula√ß√£o - em produ√ß√£o seria an√°lise real
        return {
            'hit_rate': 0.85,
            'expired_entries': 10,
            'frequent_keys': ['user:123', 'keywords:456', 'results:789']
        }
    
    def _clean_expired_cache(self):
        """Limpa cache expirado."""
        # Em produ√ß√£o, limparia entradas expiradas
        pass
    
    def _calculate_optimal_ttl(self) -> int:
        """Calcula TTL √≥timo baseado em padr√µes."""
        return 1800  # 30 minutos
    
    def _preload_frequent_data(self, keys: List[str]):
        """Pr√©-carrega dados frequentes."""
        # Em produ√ß√£o, pr√©-carregaria dados
        pass
    
    def _calculate_cache_improvement(self) -> float:
        """Calcula melhoria do cache."""
        return 5.0  # 5% de melhoria
    
    def _identify_slow_queries(self) -> List[Dict[str, Any]]:
        """Identifica queries lentas."""
        # Simula√ß√£o - em produ√ß√£o seria an√°lise real
        return [
            {
                'sql': 'SELECT * FROM keywords WHERE term LIKE "%test%"',
                'execution_time': 2.5,
                'frequency': 100
            }
        ]
    
    def _suggest_indexes(self, query: Dict[str, Any]) -> List[str]:
        """Sugere √≠ndices para queries."""
        # Simula√ß√£o - em produ√ß√£o seria an√°lise real
        return ['idx_keywords_term']
    
    def _optimize_query_structure(self, query: Dict[str, Any]) -> Optional[str]:
        """Otimiza estrutura da query."""
        # Simula√ß√£o - em produ√ß√£o seria otimiza√ß√£o real
        return 'SELECT id, term FROM keywords WHERE term LIKE "test%"'
    
    def _calculate_query_improvement(self) -> float:
        """Calcula melhoria de queries."""
        return 15.0  # 15% de melhoria
    
    def _reduce_cache_size(self):
        """Reduz tamanho do cache."""
        # Em produ√ß√£o, reduziria tamanho do cache
        pass
    
    def _optimize_data_structures(self):
        """Otimiza estruturas de dados."""
        # Em produ√ß√£o, otimizaria estruturas
        pass
    
    def _calculate_memory_improvement(self) -> float:
        """Calcula melhoria de mem√≥ria."""
        return 10.0  # 10% de melhoria
    
    def _generate_recommendations(self) -> List[str]:
        """Gera recomenda√ß√µes de otimiza√ß√£o."""
        recommendations = []
        
        if self.current_metrics.memory_usage > 0.8:
            recommendations.append("Considerar aumento de mem√≥ria ou otimiza√ß√£o de c√≥digo")
        
        if self.current_metrics.cache_hit_rate < 0.7:
            recommendations.append("Otimizar estrat√©gia de cache e TTL")
        
        if self.current_metrics.query_time > 1.0:
            recommendations.append("Revisar e otimizar queries de banco de dados")
        
        if self.current_metrics.error_rate > 0.05:
            recommendations.append("Investigar e corrigir fontes de erro")
        
        return recommendations


# Decorator para otimiza√ß√£o autom√°tica
def optimize_performance(optimizer: PerformanceOptimizer):
    """Decorator para otimiza√ß√£o autom√°tica de fun√ß√µes."""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            
            try:
                result = func(*args, **kwargs)
                
                # Registrar m√©tricas
                execution_time = time.time() - start_time
                optimizer.metrics_collector.record_metric(
                    f"function.{func.__name__}.execution_time",
                    execution_time
                )
                
                return result
                
            except Exception as e:
                # Registrar erro
                optimizer.metrics_collector.record_metric(
                    f"function.{func.__name__}.error",
                    1
                )
                raise
                
        return wrapper
    return decorator


# Fun√ß√£o global para inicializar otimizador
def initialize_performance_optimizer(config: Optional[OptimizationConfig] = None) -> PerformanceOptimizer:
    """Inicializa o otimizador de performance global."""
    if config is None:
        config = OptimizationConfig()
    
    optimizer = PerformanceOptimizer(config)
    optimizer.start_monitoring()
    
    logger.info("Otimizador de performance inicializado globalmente")
    return optimizer


# Inst√¢ncia global
_global_optimizer: Optional[PerformanceOptimizer] = None


def get_global_optimizer() -> Optional[PerformanceOptimizer]:
    """Obt√©m a inst√¢ncia global do otimizador."""
    return _global_optimizer


def set_global_optimizer(optimizer: PerformanceOptimizer):
    """Define a inst√¢ncia global do otimizador."""
    global _global_optimizer
    _global_optimizer = optimizer 