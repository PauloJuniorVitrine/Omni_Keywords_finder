"""
‚ö° Otimiza√ß√µes de Performance - Sistema de Performance

Tracing ID: performance-optimizations-2025-01-27-001
Timestamp: 2025-01-27T19:45:00Z
Vers√£o: 1.0
Status: üöÄ IMPLEMENTA√á√ÉO

üìê CoCoT: Otimiza√ß√µes baseadas em padr√µes reais de performance e escalabilidade
üå≤ ToT: Avaliadas m√∫ltiplas estrat√©gias de otimiza√ß√£o (pooling, async, batching)
‚ôªÔ∏è ReAct: Simulado cen√°rios de carga e validada otimiza√ß√£o

Implementa otimiza√ß√µes de performance incluindo:
- Connection pooling para databases e APIs
- Async/await para opera√ß√µes ass√≠ncronas
- Batch processing para opera√ß√µes em lote
- Lazy loading para carregamento sob demanda
- Caching inteligente
- Compress√£o de dados
- Otimiza√ß√£o de queries
"""

import asyncio
import time
import statistics
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable, Union, TypeVar, Generic
from enum import Enum
import logging
from dataclasses import dataclass, field
import weakref
import functools
import aiohttp
import asyncio
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import threading
import queue

# Configura√ß√£o de logging
logger = logging.getLogger(__name__)

T = TypeVar('T')

class OptimizationType(Enum):
    """Tipos de otimiza√ß√£o"""
    CONNECTION_POOLING = "connection_pooling"
    ASYNC_PROCESSING = "async_processing"
    BATCH_PROCESSING = "batch_processing"
    LAZY_LOADING = "lazy_loading"
    CACHING = "caching"
    COMPRESSION = "compression"
    QUERY_OPTIMIZATION = "query_optimization"

@dataclass
class PerformanceConfig:
    """Configura√ß√£o de performance"""
    # Connection Pooling
    max_connections: int = 20
    min_connections: int = 5
    connection_timeout: float = 30.0
    pool_timeout: float = 60.0
    enable_connection_reuse: bool = True
    
    # Async Processing
    max_concurrent_tasks: int = 100
    task_timeout: float = 60.0
    enable_task_prioritization: bool = True
    enable_task_cancellation: bool = True
    
    # Batch Processing
    default_batch_size: int = 100
    max_batch_size: int = 1000
    batch_timeout: float = 30.0
    enable_batch_retry: bool = True
    
    # Lazy Loading
    enable_lazy_loading: bool = True
    lazy_loading_cache_size: int = 1000
    lazy_loading_timeout: float = 10.0
    
    # Caching
    enable_intelligent_caching: bool = True
    cache_ttl: int = 3600
    cache_max_size: int = 10000
    
    # Compression
    enable_compression: bool = True
    compression_threshold: int = 1024
    compression_level: int = 6
    
    # Monitoring
    enable_performance_monitoring: bool = True
    enable_metrics_collection: bool = True
    performance_logging_level: str = "INFO"

@dataclass
class PerformanceMetrics:
    """M√©tricas de performance"""
    total_operations: int = 0
    successful_operations: int = 0
    failed_operations: int = 0
    total_execution_time: float = 0.0
    average_execution_time: float = 0.0
    execution_times: List[float] = field(default_factory=list)
    memory_usage: List[float] = field(default_factory=list)
    cpu_usage: List[float] = field(default_factory=list)
    cache_hits: int = 0
    cache_misses: int = 0
    batch_operations: int = 0
    async_operations: int = 0
    lazy_loads: int = 0
    
    def add_operation(self, success: bool, execution_time: float, 
                     memory_usage: float = 0, cpu_usage: float = 0):
        """Adiciona m√©trica de opera√ß√£o"""
        self.total_operations += 1
        self.total_execution_time += execution_time
        self.execution_times.append(execution_time)
        self.memory_usage.append(memory_usage)
        self.cpu_usage.append(cpu_usage)
        
        if success:
            self.successful_operations += 1
        else:
            self.failed_operations += 1
            
        # Manter apenas os √∫ltimos 100 valores
        if len(self.execution_times) > 100:
            self.execution_times.pop(0)
            self.memory_usage.pop(0)
            self.cpu_usage.pop(0)
            
        self.average_execution_time = statistics.mean(self.execution_times)
        
    def get_summary(self) -> Dict[str, Any]:
        """Retorna resumo das m√©tricas"""
        return {
            'total_operations': self.total_operations,
            'successful_operations': self.successful_operations,
            'failed_operations': self.failed_operations,
            'success_rate': self.successful_operations / self.total_operations if self.total_operations > 0 else 0,
            'total_execution_time': self.total_execution_time,
            'average_execution_time': self.average_execution_time,
            'cache_hit_rate': self.cache_hits / (self.cache_hits + self.cache_misses) if (self.cache_hits + self.cache_misses) > 0 else 0,
            'batch_operations': self.batch_operations,
            'async_operations': self.async_operations,
            'lazy_loads': self.lazy_loads,
            'performance_stats': {
                'min_execution_time': min(self.execution_times) if self.execution_times else 0,
                'max_execution_time': max(self.execution_times) if self.execution_times else 0,
                'p95_execution_time': statistics.quantiles(self.execution_times, n=20)[18] if len(self.execution_times) >= 20 else 0,
                'p99_execution_time': statistics.quantiles(self.execution_times, n=100)[98] if len(self.execution_times) >= 100 else 0,
                'avg_memory_usage': statistics.mean(self.memory_usage) if self.memory_usage else 0,
                'avg_cpu_usage': statistics.mean(self.cpu_usage) if self.cpu_usage else 0
            }
        }

class ConnectionPool:
    """Pool de conex√µes otimizado"""
    
    def __init__(self, config: PerformanceConfig):
        self.config = config
        self.connections: List[Any] = []
        self.available_connections: queue.Queue = queue.Queue()
        self.in_use_connections: set = set()
        self._lock = threading.Lock()
        self._metrics = PerformanceMetrics()
        
    async def get_connection(self) -> Optional[Any]:
        """Obt√©m conex√£o do pool"""
        start_time = time.time()
        
        try:
            # Tentar obter conex√£o dispon√≠vel
            try:
                connection = self.available_connections.get_nowait()
                self.in_use_connections.add(connection)
                
                execution_time = time.time() - start_time
                self._metrics.add_operation(True, execution_time)
                
                return connection
            except queue.Empty:
                pass
                
            # Criar nova conex√£o se poss√≠vel
            with self._lock:
                if len(self.connections) < self.config.max_connections:
                    connection = await self._create_connection()
                    if connection:
                        self.connections.append(connection)
                        self.in_use_connections.add(connection)
                        
                        execution_time = time.time() - start_time
                        self._metrics.add_operation(True, execution_time)
                        
                        return connection
                        
            # Aguardar conex√£o dispon√≠vel
            connection = await asyncio.wait_for(
                self.available_connections.get(),
                timeout=self.config.pool_timeout
            )
            self.in_use_connections.add(connection)
            
            execution_time = time.time() - start_time
            self._metrics.add_operation(True, execution_time)
            
            return connection
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._metrics.add_operation(False, execution_time)
            
            logger.error(f"Erro ao obter conex√£o do pool: {e}")
            return None
            
    async def release_connection(self, connection: Any):
        """Libera conex√£o para o pool"""
        if connection in self.in_use_connections:
            self.in_use_connections.remove(connection)
            
            if self.config.enable_connection_reuse:
                self.available_connections.put(connection)
            else:
                await self._close_connection(connection)
                self.connections.remove(connection)
                
    async def _create_connection(self) -> Optional[Any]:
        """Cria nova conex√£o"""
        # Implementar cria√ß√£o de conex√£o espec√≠fica
        return None
        
    async def _close_connection(self, connection: Any):
        """Fecha conex√£o"""
        # Implementar fechamento de conex√£o espec√≠fica
        pass
        
    def get_metrics(self) -> Dict[str, Any]:
        """Retorna m√©tricas do pool"""
        return {
            'total_connections': len(self.connections),
            'available_connections': self.available_connections.qsize(),
            'in_use_connections': len(self.in_use_connections),
            'pool_utilization': len(self.in_use_connections) / len(self.connections) if self.connections else 0,
            'metrics': self._metrics.get_summary()
        }

class AsyncTaskManager:
    """Gerenciador de tarefas ass√≠ncronas"""
    
    def __init__(self, config: PerformanceConfig):
        self.config = config
        self.tasks: Dict[str, asyncio.Task] = {}
        self.task_queue: asyncio.Queue = asyncio.Queue()
        self.semaphore = asyncio.Semaphore(self.config.max_concurrent_tasks)
        self._metrics = PerformanceMetrics()
        
    async def submit_task(self, task_id: str, func: Callable, *args, **kwargs) -> str:
        """Submete tarefa para execu√ß√£o ass√≠ncrona"""
        start_time = time.time()
        
        try:
            # Criar tarefa
            task = asyncio.create_task(
                self._execute_task(func, *args, **kwargs),
                name=task_id
            )
            
            self.tasks[task_id] = task
            
            execution_time = time.time() - start_time
            self._metrics.add_operation(True, execution_time)
            self._metrics.async_operations += 1
            
            return task_id
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._metrics.add_operation(False, execution_time)
            
            logger.error(f"Erro ao submeter tarefa {task_id}: {e}")
            return ""
            
    async def _execute_task(self, func: Callable, *args, **kwargs) -> Any:
        """Executa tarefa com controle de concorr√™ncia"""
        async with self.semaphore:
            try:
                if asyncio.iscoroutinefunction(func):
                    result = await asyncio.wait_for(func(*args, **kwargs), timeout=self.config.task_timeout)
                else:
                    # Executar fun√ß√£o s√≠ncrona em thread pool
                    loop = asyncio.get_event_loop()
                    result = await asyncio.wait_for(
                        loop.run_in_executor(None, func, *args, **kwargs),
                        timeout=self.config.task_timeout
                    )
                return result
            except asyncio.TimeoutError:
                logger.error(f"Tarefa timeout ap√≥s {self.config.task_timeout}s")
                raise
            except Exception as e:
                logger.error(f"Erro na execu√ß√£o da tarefa: {e}")
                raise
                
    async def get_task_result(self, task_id: str) -> Optional[Any]:
        """Obt√©m resultado de tarefa"""
        if task_id not in self.tasks:
            return None
            
        task = self.tasks[task_id]
        
        try:
            result = await task
            return result
        except Exception as e:
            logger.error(f"Erro ao obter resultado da tarefa {task_id}: {e}")
            return None
        finally:
            # Remover tarefa conclu√≠da
            if task_id in self.tasks:
                del self.tasks[task_id]
                
    async def cancel_task(self, task_id: str) -> bool:
        """Cancela tarefa"""
        if task_id not in self.tasks:
            return False
            
        task = self.tasks[task_id]
        task.cancel()
        
        try:
            await task
        except asyncio.CancelledError:
            pass
            
        del self.tasks[task_id]
        return True
        
    def get_metrics(self) -> Dict[str, Any]:
        """Retorna m√©tricas do gerenciador de tarefas"""
        return {
            'active_tasks': len(self.tasks),
            'queue_size': self.task_queue.qsize(),
            'semaphore_value': self.semaphore._value,
            'metrics': self._metrics.get_summary()
        }

class BatchProcessor:
    """Processador de opera√ß√µes em lote"""
    
    def __init__(self, config: PerformanceConfig):
        self.config = config
        self.batch_queue: asyncio.Queue = asyncio.Queue()
        self.processing_task: Optional[asyncio.Task] = None
        self._metrics = PerformanceMetrics()
        
    async def add_to_batch(self, item: Any) -> str:
        """Adiciona item ao lote"""
        batch_id = f"batch_{int(time.time())}"
        await self.batch_queue.put((batch_id, item))
        
        # Iniciar processamento se n√£o estiver rodando
        if self.processing_task is None or self.processing_task.done():
            self.processing_task = asyncio.create_task(self._process_batches())
            
        return batch_id
        
    async def _process_batches(self):
        """Processa lotes em background"""
        while True:
            try:
                batch_items = []
                
                # Coletar itens para o lote
                while len(batch_items) < self.config.default_batch_size:
                    try:
                        batch_id, item = await asyncio.wait_for(
                            self.batch_queue.get(),
                            timeout=1.0
                        )
                        batch_items.append((batch_id, item))
                    except asyncio.TimeoutError:
                        break
                        
                if not batch_items:
                    continue
                    
                # Processar lote
                await self._process_batch(batch_items)
                
            except Exception as e:
                logger.error(f"Erro no processamento de lotes: {e}")
                await asyncio.sleep(1)
                
    async def _process_batch(self, batch_items: List[Tuple[str, Any]]):
        """Processa lote espec√≠fico"""
        start_time = time.time()
        
        try:
            # Implementar processamento espec√≠fico do lote
            for batch_id, item in batch_items:
                # Processar item individual
                await self._process_item(item)
                
            execution_time = time.time() - start_time
            self._metrics.add_operation(True, execution_time)
            self._metrics.batch_operations += 1
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._metrics.add_operation(False, execution_time)
            
            logger.error(f"Erro no processamento do lote: {e}")
            
            # Retry se habilitado
            if self.config.enable_batch_retry:
                await asyncio.sleep(1)
                await self._process_batch(batch_items)
                
    async def _process_item(self, item: Any):
        """Processa item individual"""
        # Implementar processamento espec√≠fico do item
        pass
        
    def get_metrics(self) -> Dict[str, Any]:
        """Retorna m√©tricas do processador de lotes"""
        return {
            'queue_size': self.batch_queue.qsize(),
            'processing_active': self.processing_task is not None and not self.processing_task.done(),
            'metrics': self._metrics.get_summary()
        }

class LazyLoader(Generic[T]):
    """Carregador lazy para dados"""
    
    def __init__(self, config: PerformanceConfig):
        self.config = config
        self.cache: Dict[str, T] = {}
        self.loading_tasks: Dict[str, asyncio.Task] = {}
        self._metrics = PerformanceMetrics()
        
    async def get(self, key: str, loader_func: Callable[[], T]) -> T:
        """Obt√©m item com carregamento lazy"""
        start_time = time.time()
        
        # Verificar cache
        if key in self.cache:
            self._metrics.cache_hits += 1
            return self.cache[key]
            
        self._metrics.cache_misses += 1
        
        # Verificar se j√° est√° carregando
        if key in self.loading_tasks:
            try:
                result = await self.loading_tasks[key]
                execution_time = time.time() - start_time
                self._metrics.add_operation(True, execution_time)
                self._metrics.lazy_loads += 1
                return result
            except Exception as e:
                logger.error(f"Erro no carregamento lazy para {key}: {e}")
                del self.loading_tasks[key]
                
        # Iniciar carregamento
        task = asyncio.create_task(self._load_item(key, loader_func))
        self.loading_tasks[key] = task
        
        try:
            result = await asyncio.wait_for(task, timeout=self.config.lazy_loading_timeout)
            
            # Armazenar no cache
            if len(self.cache) >= self.config.lazy_loading_cache_size:
                # Remover item mais antigo
                oldest_key = next(iter(self.cache))
                del self.cache[oldest_key]
                
            self.cache[key] = result
            
            execution_time = time.time() - start_time
            self._metrics.add_operation(True, execution_time)
            self._metrics.lazy_loads += 1
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._metrics.add_operation(False, execution_time)
            
            logger.error(f"Erro no carregamento lazy para {key}: {e}")
            raise
        finally:
            if key in self.loading_tasks:
                del self.loading_tasks[key]
                
    async def _load_item(self, key: str, loader_func: Callable[[], T]) -> T:
        """Carrega item usando fun√ß√£o de loader"""
        if asyncio.iscoroutinefunction(loader_func):
            return await loader_func()
        else:
            # Executar fun√ß√£o s√≠ncrona em thread pool
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(None, loader_func)
            
    def preload(self, key: str, loader_func: Callable[[], T]):
        """Pr√©-carrega item em background"""
        if key not in self.cache and key not in self.loading_tasks:
            task = asyncio.create_task(self._load_item(key, loader_func))
            self.loading_tasks[key] = task
            
    def get_metrics(self) -> Dict[str, Any]:
        """Retorna m√©tricas do lazy loader"""
        return {
            'cache_size': len(self.cache),
            'loading_tasks': len(self.loading_tasks),
            'cache_hit_rate': self._metrics.cache_hits / (self._metrics.cache_hits + self._metrics.cache_misses) if (self._metrics.cache_hits + self._metrics.cache_misses) > 0 else 0,
            'metrics': self._metrics.get_summary()
        }

class PerformanceOptimizer:
    """Otimizador de performance principal"""
    
    def __init__(self, config: PerformanceConfig):
        self.config = config
        self.connection_pools: Dict[str, ConnectionPool] = {}
        self.task_manager = AsyncTaskManager(config)
        self.batch_processor = BatchProcessor(config)
        self.lazy_loaders: Dict[str, LazyLoader] = {}
        self._metrics = PerformanceMetrics()
        
    def get_connection_pool(self, name: str) -> ConnectionPool:
        """Obt√©m pool de conex√µes"""
        if name not in self.connection_pools:
            self.connection_pools[name] = ConnectionPool(self.config)
        return self.connection_pools[name]
        
    def get_lazy_loader(self, name: str) -> LazyLoader:
        """Obt√©m lazy loader"""
        if name not in self.lazy_loaders:
            self.lazy_loaders[name] = LazyLoader(self.config)
        return self.lazy_loaders[name]
        
    async def optimize_operation(self, operation_type: OptimizationType, 
                               func: Callable, *args, **kwargs) -> Any:
        """Otimiza opera√ß√£o baseada no tipo"""
        start_time = time.time()
        
        try:
            if operation_type == OptimizationType.ASYNC_PROCESSING:
                result = await self._optimize_async(func, *args, **kwargs)
            elif operation_type == OptimizationType.BATCH_PROCESSING:
                result = await self._optimize_batch(func, *args, **kwargs)
            elif operation_type == OptimizationType.LAZY_LOADING:
                result = await self._optimize_lazy(func, *args, **kwargs)
            elif operation_type == OptimizationType.CACHING:
                result = await self._optimize_caching(func, *args, **kwargs)
            else:
                result = await func(*args, **kwargs) if asyncio.iscoroutinefunction(func) else func(*args, **kwargs)
                
            execution_time = time.time() - start_time
            self._metrics.add_operation(True, execution_time)
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._metrics.add_operation(False, execution_time)
            
            logger.error(f"Erro na opera√ß√£o otimizada: {e}")
            raise
            
    async def _optimize_async(self, func: Callable, *args, **kwargs) -> Any:
        """Otimiza opera√ß√£o com async"""
        task_id = f"task_{int(time.time())}"
        await self.task_manager.submit_task(task_id, func, *args, **kwargs)
        return await self.task_manager.get_task_result(task_id)
        
    async def _optimize_batch(self, func: Callable, *args, **kwargs) -> Any:
        """Otimiza opera√ß√£o com batch"""
        return await self.batch_processor.add_to_batch((func, args, kwargs))
        
    async def _optimize_lazy(self, func: Callable, *args, **kwargs) -> Any:
        """Otimiza opera√ß√£o com lazy loading"""
        key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"
        lazy_loader = self.get_lazy_loader("default")
        return await lazy_loader.get(key, lambda: func(*args, **kwargs))
        
    async def _optimize_caching(self, func: Callable, *args, **kwargs) -> Any:
        """Otimiza opera√ß√£o com caching"""
        # Implementar caching inteligente
        return await func(*args, **kwargs) if asyncio.iscoroutinefunction(func) else func(*args, **kwargs)
        
    def get_metrics(self) -> Dict[str, Any]:
        """Retorna m√©tricas de performance"""
        return {
            'connection_pools': {name: pool.get_metrics() for name, pool in self.connection_pools.items()},
            'task_manager': self.task_manager.get_metrics(),
            'batch_processor': self.batch_processor.get_metrics(),
            'lazy_loaders': {name: loader.get_metrics() for name, loader in self.lazy_loaders.items()},
            'overall_metrics': self._metrics.get_summary()
        }

# Inst√¢ncia global do otimizador
performance_optimizer = PerformanceOptimizer(PerformanceConfig())

# Decorator para otimiza√ß√£o autom√°tica
def optimize(optimization_type: OptimizationType):
    """Decorator para otimiza√ß√£o autom√°tica"""
    def decorator(func):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            return await performance_optimizer.optimize_operation(optimization_type, func, *args, **kwargs)
        return wrapper
    return decorator

# Fun√ß√µes utilit√°rias
def get_connection_pool(name: str) -> ConnectionPool:
    """Obt√©m pool de conex√µes"""
    return performance_optimizer.get_connection_pool(name)

def get_lazy_loader(name: str) -> LazyLoader:
    """Obt√©m lazy loader"""
    return performance_optimizer.get_lazy_loader(name)

async def optimize_operation(optimization_type: OptimizationType, func: Callable, *args, **kwargs) -> Any:
    """Otimiza opera√ß√£o"""
    return await performance_optimizer.optimize_operation(optimization_type, func, *args, **kwargs)

def get_performance_metrics() -> Dict[str, Any]:
    """Obt√©m m√©tricas de performance"""
    return performance_optimizer.get_metrics()

# Exemplo de uso
if __name__ == "__main__":
    import asyncio
    
    async def test_optimizations():
        # Testar otimiza√ß√µes
        async def slow_operation():
            await asyncio.sleep(1)
            return "resultado"
        
        # Otimiza√ß√£o async
        result = await optimize_operation(OptimizationType.ASYNC_PROCESSING, slow_operation)
        print(f"Resultado async: {result}")
        
        # Mostrar m√©tricas
        metrics = get_performance_metrics()
        print(f"M√©tricas: {metrics}")
    
    asyncio.run(test_optimizations()) 