# üß™ Testes de Carga - Omni Keywords Finder
# üìÖ Semana 7-8: Integration & E2E (Meta: 98% cobertura)
# üéØ Tracing ID: TESTES_98_COBERTURA_001_20250127
# üìù Prompt: Implementar testes de carga para validar performance
# üîß Ruleset: enterprise_control_layer.yaml

"""
Testes de Carga e Performance
=============================

Este m√≥dulo implementa testes de carga para validar:
- Performance sob carga
- Escalabilidade do sistema
- Limites de capacidade
- Estabilidade em longo prazo
- Recupera√ß√£o de falhas

Cobertura Alvo: 98% (Semana 7-8)
"""

import pytest
import asyncio
import time
import statistics
from typing import Dict, Any, List, Tuple
from unittest.mock import patch, MagicMock
import httpx
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from datetime import datetime, timedelta


@dataclass
class LoadTestResult:
    """Resultado de teste de carga."""
    endpoint: str
    total_requests: int
    successful_requests: int
    failed_requests: int
    avg_response_time: float
    min_response_time: float
    max_response_time: float
    p95_response_time: float
    p99_response_time: float
    requests_per_second: float
    error_rate: float
    test_duration: float


class LoadTestingFramework:
    """Framework para testes de carga."""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results: List[LoadTestResult] = []
        
    async def run_concurrent_requests(
        self, 
        endpoint: str, 
        method: str = "GET",
        payload: Dict = None,
        headers: Dict = None,
        concurrent_users: int = 10,
        requests_per_user: int = 10,
        timeout: float = 30.0
    ) -> LoadTestResult:
        """
        Executa requisi√ß√µes concorrentes para teste de carga.
        
        Args:
            endpoint: Endpoint a ser testado
            method: M√©todo HTTP
            payload: Dados da requisi√ß√£o
            headers: Headers HTTP
            concurrent_users: N√∫mero de usu√°rios simult√¢neos
            requests_per_user: Requisi√ß√µes por usu√°rio
            timeout: Timeout por requisi√ß√£o
            
        Returns:
            LoadTestResult com m√©tricas de performance
        """
        start_time = time.time()
        response_times = []
        successful_requests = 0
        failed_requests = 0
        
        async def make_request(user_id: int, request_id: int) -> Tuple[bool, float]:
            """Faz uma requisi√ß√£o individual."""
            try:
                request_start = time.time()
                
                async with httpx.AsyncClient(timeout=timeout) as client:
                    if method.upper() == "GET":
                        response = await client.get(
                            f"{self.base_url}{endpoint}",
                            headers=headers
                        )
                    elif method.upper() == "POST":
                        response = await client.post(
                            f"{self.base_url}{endpoint}",
                            json=payload,
                            headers=headers
                        )
                    elif method.upper() == "PUT":
                        response = await client.put(
                            f"{self.base_url}{endpoint}",
                            json=payload,
                            headers=headers
                        )
                    elif method.upper() == "DELETE":
                        response = await client.delete(
                            f"{self.base_url}{endpoint}",
                            headers=headers
                        )
                    else:
                        raise ValueError(f"M√©todo HTTP n√£o suportado: {method}")
                
                request_time = time.time() - request_start
                
                if response.status_code < 400:
                    return True, request_time
                else:
                    return False, request_time
                    
            except Exception as e:
                # Falha na requisi√ß√£o
                return False, 0.0
        
        # Executar requisi√ß√µes concorrentes
        tasks = []
        for user_id in range(concurrent_users):
            for request_id in range(requests_per_user):
                task = make_request(user_id, request_id)
                tasks.append(task)
        
        # Aguardar todas as requisi√ß√µes
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Processar resultados
        for result in results:
            if isinstance(result, Exception):
                failed_requests += 1
            else:
                success, response_time = result
                if success:
                    successful_requests += 1
                    response_times.append(response_time)
                else:
                    failed_requests += 1
        
        total_requests = concurrent_users * requests_per_user
        test_duration = time.time() - start_time
        
        # Calcular m√©tricas
        if response_times:
            avg_response_time = statistics.mean(response_times)
            min_response_time = min(response_times)
            max_response_time = max(response_times)
            
            # Percentis
            sorted_times = sorted(response_times)
            p95_index = int(len(sorted_times) * 0.95)
            p99_index = int(len(sorted_times) * 0.99)
            
            p95_response_time = sorted_times[p95_index] if p95_index < len(sorted_times) else max_response_time
            p99_response_time = sorted_times[p99_index] if p99_index < len(sorted_times) else max_response_time
        else:
            avg_response_time = min_response_time = max_response_time = p95_response_time = p99_response_time = 0.0
        
        requests_per_second = total_requests / test_duration if test_duration > 0 else 0.0
        error_rate = failed_requests / total_requests if total_requests > 0 else 0.0
        
        result = LoadTestResult(
            endpoint=endpoint,
            total_requests=total_requests,
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            avg_response_time=avg_response_time,
            min_response_time=min_response_time,
            max_response_time=max_response_time,
            p95_response_time=p95_response_time,
            p99_response_time=p99_response_time,
            requests_per_second=requests_per_second,
            error_rate=error_rate,
            test_duration=test_duration
        )
        
        self.results.append(result)
        return result
    
    def generate_load_report(self) -> str:
        """Gera relat√≥rio de testes de carga."""
        if not self.results:
            return "Nenhum teste de carga executado."
        
        report = []
        report.append("=" * 80)
        report.append("üìä RELAT√ìRIO DE TESTES DE CARGA")
        report.append("=" * 80)
        report.append(f"Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"Total de Testes: {len(self.results)}")
        report.append("")
        
        for result in self.results:
            report.append(f"üîó Endpoint: {result.endpoint}")
            report.append(f"   üìà Total de Requisi√ß√µes: {result.total_requests}")
            report.append(f"   ‚úÖ Sucessos: {result.successful_requests}")
            report.append(f"   ‚ùå Falhas: {result.failed_requests}")
            report.append(f"   ‚è±Ô∏è  Tempo M√©dio: {result.avg_response_time:.3f}s")
            report.append(f"   üöÄ RPS: {result.requests_per_second:.2f}")
            report.append(f"   üìä Taxa de Erro: {result.error_rate:.2%}")
            report.append(f"   üìä P95: {result.p95_response_time:.3f}s")
            report.append(f"   üìä P99: {result.p99_response_time:.3f}s")
            report.append("")
        
        # Resumo geral
        total_requests = sum(r.total_requests for r in self.results)
        total_successful = sum(r.successful_requests for r in self.results)
        total_failed = sum(r.failed_requests for r in self.results)
        overall_error_rate = total_failed / total_requests if total_requests > 0 else 0.0
        
        report.append("üìã RESUMO GERAL")
        report.append("-" * 40)
        report.append(f"Total de Requisi√ß√µes: {total_requests}")
        report.append(f"Total de Sucessos: {total_successful}")
        report.append(f"Total de Falhas: {total_failed}")
        report.append(f"Taxa de Erro Geral: {overall_error_rate:.2%}")
        report.append("")
        
        return "\n".join(report)


class TestLoadTesting:
    """Testes de carga para o sistema."""
    
    @pytest.fixture(autouse=True)
    def setup_load_testing(self):
        """Configura ambiente de teste de carga."""
        self.load_tester = LoadTestingFramework()
        self.base_url = "http://localhost:8000"
        
        # Configura√ß√µes de teste
        self.test_configs = {
            "light_load": {"users": 5, "requests": 10},
            "medium_load": {"users": 20, "requests": 25},
            "heavy_load": {"users": 50, "requests": 50},
            "stress_test": {"users": 100, "requests": 100}
        }
        
        yield
        
        # Limpeza
        pass
    
    async def test_keyword_search_light_load(self):
        """
        Testa performance de busca de keywords sob carga leve.
        
        Cen√°rio: 5 usu√°rios simult√¢neos, 10 requisi√ß√µes cada
        """
        result = await self.load_tester.run_concurrent_requests(
            endpoint="/api/v1/keywords/search",
            method="GET",
            payload=None,
            headers=None,
            concurrent_users=self.test_configs["light_load"]["users"],
            requests_per_user=self.test_configs["light_load"]["requests"]
        )
        
        # Valida√ß√µes de performance
        assert result.successful_requests > 0
        assert result.error_rate < 0.05  # M√°ximo 5% de erro
        assert result.avg_response_time < 1.0  # M√°ximo 1 segundo
        assert result.p95_response_time < 2.0  # P95 < 2 segundos
        assert result.requests_per_second > 10  # M√≠nimo 10 RPS
    
    async def test_keyword_analysis_medium_load(self):
        """
        Testa performance de an√°lise de keywords sob carga m√©dia.
        
        Cen√°rio: 20 usu√°rios simult√¢neos, 25 requisi√ß√µes cada
        """
        payload = {
            "keywords": ["python", "machine learning", "data science"],
            "config": {
                "analysis_type": "basic",
                "language": "pt-BR",
                "region": "BR"
            }
        }
        
        result = await self.load_tester.run_concurrent_requests(
            endpoint="/api/v1/analysis/create",
            method="POST",
            payload=payload,
            headers=None,
            concurrent_users=self.test_configs["medium_load"]["users"],
            requests_per_user=self.test_configs["medium_load"]["requests"]
        )
        
        # Valida√ß√µes de performance
        assert result.successful_requests > 0
        assert result.error_rate < 0.10  # M√°ximo 10% de erro
        assert result.avg_response_time < 3.0  # M√°ximo 3 segundos
        assert result.p95_response_time < 5.0  # P95 < 5 segundos
        assert result.requests_per_second > 50  # M√≠nimo 50 RPS
    
    async def test_dashboard_heavy_load(self):
        """
        Testa performance do dashboard sob carga pesada.
        
        Cen√°rio: 50 usu√°rios simult√¢neos, 50 requisi√ß√µes cada
        """
        result = await self.load_tester.run_concurrent_requests(
            endpoint="/api/v1/dashboard/overview",
            method="GET",
            payload=None,
            headers=None,
            concurrent_users=self.test_configs["heavy_load"]["users"],
            requests_per_user=self.test_configs["heavy_load"]["requests"]
        )
        
        # Valida√ß√µes de performance
        assert result.successful_requests > 0
        assert result.error_rate < 0.15  # M√°ximo 15% de erro
        assert result.avg_response_time < 2.0  # M√°ximo 2 segundos
        assert result.p95_response_time < 4.0  # P95 < 4 segundos
        assert result.requests_per_second > 100  # M√≠nimo 100 RPS
    
    async def test_stress_test_system_limits(self):
        """
        Testa limites do sistema sob estresse extremo.
        
        Cen√°rio: 100 usu√°rios simult√¢neos, 100 requisi√ß√µes cada
        """
        result = await self.load_tester.run_concurrent_requests(
            endpoint="/api/v1/keywords/search",
            method="GET",
            payload=None,
            headers=None,
            concurrent_users=self.test_configs["stress_test"]["users"],
            requests_per_user=self.test_configs["stress_test"]["requests"]
        )
        
        # Em teste de estresse, esperamos algumas falhas
        assert result.successful_requests > 0
        assert result.error_rate < 0.30  # M√°ximo 30% de erro
        assert result.avg_response_time < 5.0  # M√°ximo 5 segundos
        assert result.p95_response_time < 10.0  # P95 < 10 segundos
    
    async def test_concurrent_analysis_operations(self):
        """
        Testa opera√ß√µes concorrentes de an√°lise.
        
        Cen√°rio: M√∫ltiplas an√°lises simult√¢neas
        """
        # Criar m√∫ltiplas an√°lises simultaneamente
        analysis_payloads = [
            {
                "keywords": [f"keyword_{i}"],
                "config": {"analysis_type": "basic"}
            }
            for i in range(20)
        ]
        
        results = []
        for payload in analysis_payloads:
            result = await self.load_tester.run_concurrent_requests(
                endpoint="/api/v1/analysis/create",
                method="POST",
                payload=payload,
                concurrent_users=1,
                requests_per_user=1
            )
            results.append(result)
        
        # Validar que todas as an√°lises foram iniciadas
        successful_analyses = sum(1 for r in results if r.successful_requests > 0)
        assert successful_analyses >= 15  # Pelo menos 75% de sucesso
    
    async def test_database_connection_pool_under_load(self):
        """
        Testa pool de conex√µes do banco sob carga.
        
        Cen√°rio: M√∫ltiplas opera√ß√µes de banco simult√¢neas
        """
        # Simular m√∫ltiplas opera√ß√µes de banco
        db_operations = [
            "/api/v1/keywords/list",
            "/api/v1/analysis/list",
            "/api/v1/user/profile"
        ]
        
        results = []
        for endpoint in db_operations:
            result = await self.load_tester.run_concurrent_requests(
                endpoint=endpoint,
                method="GET",
                concurrent_users=10,
                requests_per_user=20
            )
            results.append(result)
        
        # Validar que pool de conex√µes est√° funcionando
        for result in results:
            assert result.error_rate < 0.10  # M√°ximo 10% de erro
            assert result.avg_response_time < 1.0  # M√°ximo 1 segundo
    
    async def test_memory_usage_under_load(self):
        """
        Testa uso de mem√≥ria sob carga.
        
        Cen√°rio: Monitoramento de recursos durante testes
        """
        # Mock de monitoramento de mem√≥ria
        with patch('psutil.virtual_memory') as mock_memory:
            mock_memory.return_value = MagicMock(
                percent=75.0,  # 75% de uso
                available=1024 * 1024 * 1024,  # 1GB dispon√≠vel
                total=4 * 1024 * 1024 * 1024  # 4GB total
            )
            
            # Executar teste de carga
            result = await self.load_tester.run_concurrent_requests(
                endpoint="/api/v1/keywords/search",
                method="GET",
                concurrent_users=30,
                requests_per_user=40
            )
            
            # Validar que sistema mant√©m performance
            assert result.successful_requests > 0
            assert result.error_rate < 0.15  # M√°ximo 15% de erro
            assert result.avg_response_time < 2.0  # M√°ximo 2 segundos
    
    async def test_network_latency_impact(self):
        """
        Testa impacto da lat√™ncia de rede na performance.
        
        Cen√°rio: Simula√ß√£o de diferentes lat√™ncias
        """
        # Mock de lat√™ncia de rede
        with patch('httpx.AsyncClient.get') as mock_get:
            # Simular diferentes lat√™ncias
            latencies = [0.1, 0.5, 1.0, 2.0]  # segundos
            
            async def delayed_response(*args, **kwargs):
                await asyncio.sleep(latencies.pop(0) if latencies else 0.1)
                return MagicMock(status_code=200, json=lambda: {"data": "test"})
            
            mock_get.side_effect = delayed_response
            
            # Executar teste com lat√™ncia simulada
            result = await self.load_tester.run_concurrent_requests(
                endpoint="/api/v1/keywords/search",
                method="GET",
                concurrent_users=10,
                requests_per_user=20
            )
            
            # Validar que sistema lida com lat√™ncia
            assert result.successful_requests > 0
            assert result.avg_response_time > 0.5  # Deve refletir lat√™ncia
    
    async def test_gradual_load_increase(self):
        """
        Testa aumento gradual de carga.
        
        Cen√°rio: Carga aumenta progressivamente para identificar breaking point
        """
        load_levels = [
            {"users": 5, "requests": 10},
            {"users": 15, "requests": 20},
            {"users": 30, "requests": 40},
            {"users": 50, "requests": 60}
        ]
        
        results = []
        for config in load_levels:
            result = await self.load_tester.run_concurrent_requests(
                endpoint="/api/v1/keywords/search",
                method="GET",
                concurrent_users=config["users"],
                requests_per_user=config["requests"]
            )
            results.append(result)
            
            # Aguardar entre n√≠veis
            await asyncio.sleep(2)
        
        # Validar degrada√ß√£o gradual (n√£o catastr√≥fica)
        for i, result in enumerate(results):
            if i > 0:  # Comparar com n√≠vel anterior
                prev_result = results[i-1]
                # Performance pode degradar, mas n√£o deve quebrar
                assert result.error_rate < 0.50  # M√°ximo 50% de erro
                assert result.avg_response_time < 10.0  # M√°ximo 10 segundos
    
    async def test_recovery_after_high_load(self):
        """
        Testa recupera√ß√£o do sistema ap√≥s carga alta.
        
        Cen√°rio: Sistema se recupera ap√≥s per√≠odo de estresse
        """
        # 1. Aplicar carga alta
        stress_result = await self.load_tester.run_concurrent_requests(
            endpoint="/api/v1/keywords/search",
            method="GET",
            concurrent_users=80,
            requests_per_user=80
        )
        
        # 2. Aguardar estabiliza√ß√£o
        await asyncio.sleep(5)
        
        # 3. Testar recupera√ß√£o com carga normal
        recovery_result = await self.load_tester.run_concurrent_requests(
            endpoint="/api/v1/keywords/search",
            method="GET",
            concurrent_users=10,
            requests_per_user=20
        )
        
        # Validar recupera√ß√£o
        assert recovery_result.error_rate < 0.05  # Deve voltar ao normal
        assert recovery_result.avg_response_time < 1.0  # Performance deve se recuperar
        assert recovery_result.requests_per_second > 10  # RPS deve se recuperar
    
    def test_load_test_report_generation(self):
        """Testa gera√ß√£o de relat√≥rios de teste de carga."""
        # Simular alguns resultados
        self.load_tester.results = [
            LoadTestResult(
                endpoint="/api/v1/keywords/search",
                total_requests=100,
                successful_requests=95,
                failed_requests=5,
                avg_response_time=0.5,
                min_response_time=0.1,
                max_response_time=2.0,
                p95_response_time=1.0,
                p99_response_time=1.5,
                requests_per_second=50.0,
                error_rate=0.05,
                test_duration=2.0
            )
        ]
        
        # Gerar relat√≥rio
        report = self.load_tester.generate_load_report()
        
        # Validar conte√∫do do relat√≥rio
        assert "RELAT√ìRIO DE TESTES DE CARGA" in report
        assert "/api/v1/keywords/search" in report
        assert "100" in report  # Total de requisi√ß√µes
        assert "95" in report   # Sucessos
        assert "5" in report    # Falhas
        assert "0.5" in report  # Tempo m√©dio
        assert "50.0" in report # RPS


# Configura√ß√£o de fixtures para testes de carga
@pytest.fixture
def load_testing_framework():
    """Framework de teste de carga."""
    return LoadTestingFramework()


@pytest.fixture
def sample_load_config():
    """Configura√ß√£o de exemplo para testes de carga."""
    return {
        "concurrent_users": 10,
        "requests_per_user": 20,
        "timeout": 30.0
    }


# Configura√ß√£o pytest para testes de carga
pytestmark = pytest.mark.asyncio
pytestmark = pytest.mark.load
pytestmark = pytest.mark.slow
