#!/usr/bin/env python3
"""
Script de Execu√ß√£o dos Testes de Ambiente - Omni Keywords Finder
Tracing ID: ENV_LOAD_TESTS_20250127_001

Este script executa todos os testes de ambiente implementados:
- Testes de staging
- Testes de ambiente similar √† produ√ß√£o
- Testes multi-regi√£o
- Gerador de dados de teste
- Configura√ß√µes de teste
- Monitoramento de testes

Autor: IA-Cursor
Data: 2025-01-27
Vers√£o: 1.0
"""

import os
import sys
import argparse
import subprocess
import time
import json
from datetime import datetime
from pathlib import Path

# Adicionar o diret√≥rio raiz ao path
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

from tests.load.medium.environment.environment_staging_test import EnvironmentStagingTest
from tests.load.medium.environment.environment_production_like_test import EnvironmentProductionLikeTest
from tests.load.medium.environment.environment_multi_region_test import EnvironmentMultiRegionTest
from tests.load.medium.environment.environment_test_data_generator import EnvironmentTestDataGenerator
from tests.load.medium.environment.environment_test_configuration import EnvironmentTestConfiguration
from tests.load.medium.environment.environment_test_monitoring import EnvironmentTestMonitoring


class EnvironmentLoadTestRunner:
    """
    Executor de testes de carga de ambiente
    """
    
    def __init__(self, host: str = "http://localhost:8000", verbose: bool = False):
        self.host = host
        self.verbose = verbose
        self.results = {}
        self.start_time = datetime.now()
        
    def log(self, message: str, level: str = "INFO"):
        """Log estruturado com timestamp"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] [{level}] {message}")
        
    def run_test(self, test_class, test_name: str) -> dict:
        """Executa um teste espec√≠fico"""
        self.log(f"Iniciando teste: {test_name}")
        
        try:
            # Criar inst√¢ncia do teste
            test_instance = test_class(host=self.host, verbose=self.verbose)
            
            # Executar teste
            start_time = time.time()
            result = test_instance.run()
            end_time = time.time()
            
            # Calcular m√©tricas
            execution_time = end_time - start_time
            success = result.get('success', False)
            
            test_result = {
                'test_name': test_name,
                'success': success,
                'execution_time': execution_time,
                'details': result,
                'timestamp': datetime.now().isoformat()
            }
            
            status = "‚úÖ SUCESSO" if success else "‚ùå FALHA"
            self.log(f"Teste {test_name} conclu√≠do: {status} ({execution_time:.2f}s)")
            
            return test_result
            
        except Exception as e:
            self.log(f"Erro no teste {test_name}: {str(e)}", "ERROR")
            return {
                'test_name': test_name,
                'success': False,
                'execution_time': 0,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def run_all_tests(self) -> dict:
        """Executa todos os testes de ambiente"""
        self.log("üöÄ Iniciando execu√ß√£o de todos os testes de ambiente")
        
        # Lista de testes a executar
        tests = [
            (EnvironmentStagingTest, "Testes de Ambiente de Staging"),
            (EnvironmentProductionLikeTest, "Testes de Ambiente Similar √† Produ√ß√£o"),
            (EnvironmentMultiRegionTest, "Testes Multi-Regi√£o"),
            (EnvironmentTestDataGenerator, "Gerador de Dados de Teste"),
            (EnvironmentTestConfiguration, "Configura√ß√µes de Teste"),
            (EnvironmentTestMonitoring, "Monitoramento de Testes")
        ]
        
        # Executar cada teste
        for test_class, test_name in tests:
            result = self.run_test(test_class, test_name)
            self.results[test_name] = result
            
            # Pequena pausa entre testes
            time.sleep(1)
        
        return self.generate_report()
    
    def generate_report(self) -> dict:
        """Gera relat√≥rio final dos testes"""
        end_time = datetime.now()
        total_time = (end_time - self.start_time).total_seconds()
        
        # Calcular estat√≠sticas
        total_tests = len(self.results)
        successful_tests = sum(1 for r in self.results.values() if r['success'])
        failed_tests = total_tests - successful_tests
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        # Tempo total de execu√ß√£o
        total_execution_time = sum(r['execution_time'] for r in self.results.values())
        
        report = {
            'summary': {
                'total_tests': total_tests,
                'successful_tests': successful_tests,
                'failed_tests': failed_tests,
                'success_rate': success_rate,
                'total_execution_time': total_execution_time,
                'total_wall_time': total_time,
                'start_time': self.start_time.isoformat(),
                'end_time': end_time.isoformat()
            },
            'results': self.results,
            'host': self.host,
            'tracing_id': 'ENV_LOAD_TESTS_20250127_001'
        }
        
        return report
    
    def print_report(self, report: dict):
        """Imprime relat√≥rio formatado"""
        summary = report['summary']
        
        print("\n" + "="*80)
        print("üìä RELAT√ìRIO DE TESTES DE AMBIENTE - OMNI KEYWORDS FINDER")
        print("="*80)
        print(f"üîó Host: {report['host']}")
        print(f"üÜî Tracing ID: {report['tracing_id']}")
        print(f"‚è∞ In√≠cio: {summary['start_time']}")
        print(f"‚è∞ Fim: {summary['end_time']}")
        print(f"‚è±Ô∏è  Tempo Total: {summary['total_wall_time']:.2f}s")
        print(f"‚ö° Tempo de Execu√ß√£o: {summary['total_execution_time']:.2f}s")
        print()
        
        print("üìà ESTAT√çSTICAS:")
        print(f"   ‚Ä¢ Total de Testes: {summary['total_tests']}")
        print(f"   ‚Ä¢ Testes Bem-sucedidos: {summary['successful_tests']}")
        print(f"   ‚Ä¢ Testes Falharam: {summary['failed_tests']}")
        print(f"   ‚Ä¢ Taxa de Sucesso: {summary['success_rate']:.1f}%")
        print()
        
        print("üìã DETALHES POR TESTE:")
        for test_name, result in report['results'].items():
            status = "‚úÖ" if result['success'] else "‚ùå"
            execution_time = result['execution_time']
            print(f"   {status} {test_name}: {execution_time:.2f}s")
            
            if not result['success'] and 'error' in result:
                print(f"      Erro: {result['error']}")
        
        print("="*80)
        
        # Status final
        if summary['success_rate'] == 100:
            print("üéâ TODOS OS TESTES PASSARAM!")
        elif summary['success_rate'] >= 80:
            print("‚ö†Ô∏è  MAIORIA DOS TESTES PASSOU - VERIFICAR FALHAS")
        else:
            print("üö® MUITOS TESTES FALHARAM - INVESTIGAR URGENTEMENTE")
        
        print("="*80)
    
    def save_report(self, report: dict, output_file: str = None):
        """Salva relat√≥rio em arquivo JSON"""
        if not output_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"environment_load_test_report_{timestamp}.json"
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            self.log(f"Relat√≥rio salvo em: {output_file}")
            return output_file
            
        except Exception as e:
            self.log(f"Erro ao salvar relat√≥rio: {str(e)}", "ERROR")
            return None


def main():
    """Fun√ß√£o principal"""
    parser = argparse.ArgumentParser(
        description="Executor de Testes de Carga de Ambiente - Omni Keywords Finder",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python run_environment_load_tests.py
  python run_environment_load_tests.py --host http://staging.example.com
  python run_environment_load_tests.py --verbose --output report.json
        """
    )
    
    parser.add_argument(
        '--host',
        default='http://localhost:8000',
        help='URL do host para testar (padr√£o: http://localhost:8000)'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Modo verboso para logs detalhados'
    )
    
    parser.add_argument(
        '--output',
        help='Arquivo de sa√≠da para o relat√≥rio JSON'
    )
    
    parser.add_argument(
        '--test',
        choices=[
            'staging',
            'production-like',
            'multi-region',
            'data-generator',
            'configuration',
            'monitoring',
            'all'
        ],
        default='all',
        help='Teste espec√≠fico a executar (padr√£o: all)'
    )
    
    args = parser.parse_args()
    
    # Criar executor
    runner = EnvironmentLoadTestRunner(host=args.host, verbose=args.verbose)
    
    try:
        if args.test == 'all':
            # Executar todos os testes
            report = runner.run_all_tests()
        else:
            # Executar teste espec√≠fico
            test_map = {
                'staging': (EnvironmentStagingTest, "Testes de Ambiente de Staging"),
                'production-like': (EnvironmentProductionLikeTest, "Testes de Ambiente Similar √† Produ√ß√£o"),
                'multi-region': (EnvironmentMultiRegionTest, "Testes Multi-Regi√£o"),
                'data-generator': (EnvironmentTestDataGenerator, "Gerador de Dados de Teste"),
                'configuration': (EnvironmentTestConfiguration, "Configura√ß√µes de Teste"),
                'monitoring': (EnvironmentTestMonitoring, "Monitoramento de Testes")
            }
            
            test_class, test_name = test_map[args.test]
            result = runner.run_test(test_class, test_name)
            report = {
                'summary': {
                    'total_tests': 1,
                    'successful_tests': 1 if result['success'] else 0,
                    'failed_tests': 0 if result['success'] else 1,
                    'success_rate': 100 if result['success'] else 0,
                    'total_execution_time': result['execution_time'],
                    'total_wall_time': result['execution_time'],
                    'start_time': runner.start_time.isoformat(),
                    'end_time': datetime.now().isoformat()
                },
                'results': {test_name: result},
                'host': args.host,
                'tracing_id': 'ENV_LOAD_TESTS_20250127_001'
            }
        
        # Imprimir relat√≥rio
        runner.print_report(report)
        
        # Salvar relat√≥rio
        if args.output:
            runner.save_report(report, args.output)
        else:
            runner.save_report(report)
        
        # C√≥digo de sa√≠da baseado no sucesso
        success_rate = report['summary']['success_rate']
        if success_rate == 100:
            sys.exit(0)  # Sucesso total
        elif success_rate >= 80:
            sys.exit(1)  # Maioria passou
        else:
            sys.exit(2)  # Muitas falhas
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Execu√ß√£o interrompida pelo usu√°rio")
        sys.exit(130)
    except Exception as e:
        print(f"\n‚ùå Erro durante execu√ß√£o: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main() 