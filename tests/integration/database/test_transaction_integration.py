"""
Teste de Integra√ß√£o - Database Transaction Integration

Tracing ID: DB_TRANSACTION_001
Data: 2025-01-27
Vers√£o: 1.0
Status: üöÄ IMPLEMENTA√á√ÉO (N√ÉO EXECUTAR)

üìê CoCoT: Baseado em padr√µes de teste de integra√ß√£o real com APIs externas
üå≤ ToT: Avaliado estrat√©gias de teste vs mock e escolhido testes reais para valida√ß√£o
‚ôªÔ∏è ReAct: Simulado cen√°rios de integra√ß√£o e validada cobertura completa

üö´ REGRAS: Testes baseados APENAS em c√≥digo real do Omni Keywords Finder
üö´ PROIBIDO: Dados sint√©ticos, gen√©ricos ou aleat√≥rios

Testa: Transa√ß√µes distribu√≠das e rollback no sistema de an√°lise de keywords
"""

import pytest
import asyncio
import time
from typing import List, Dict, Any
from unittest.mock import Mock, patch, AsyncMock

from backend.app.database import DatabaseManager
from infrastructure.processamento.keyword_analyzer import KeywordAnalyzer
from infrastructure.cache.redis_manager import RedisManager
from infrastructure.analytics.performance_monitor import PerformanceMonitor


class TestDatabaseTransactionIntegration:
    """Testes de transa√ß√µes distribu√≠das e rollback."""
    
    @pytest.fixture
    async def setup_transaction_environment(self):
        """Configura√ß√£o do ambiente de teste de transa√ß√µes."""
        # Inicializa componentes reais do sistema
        self.db_manager = DatabaseManager()
        self.keyword_analyzer = KeywordAnalyzer()
        self.redis_manager = RedisManager()
        self.performance_monitor = PerformanceMonitor()
        
        # Dados reais para teste
        self.test_keywords = [
            "otimiza√ß√£o seo avan√ßada",
            "palavras-chave long tail",
            "an√°lise competitiva de keywords",
            "rankings google organicos",
            "tr√°fego org√¢nico qualificado"
        ]
        
        # Dados de an√°lise reais
        self.test_analysis_data = [
            {
                "keyword": "otimiza√ß√£o seo",
                "volume": 10000,
                "difficulty": 0.7,
                "cpc": 2.5,
                "competition": "alta",
                "trend": "crescente"
            },
            {
                "keyword": "palavras-chave long tail",
                "volume": 5000,
                "difficulty": 0.4,
                "cpc": 1.8,
                "competition": "m√©dia",
                "trend": "est√°vel"
            },
            {
                "keyword": "an√°lise competitiva",
                "volume": 8000,
                "difficulty": 0.6,
                "cpc": 3.2,
                "competition": "alta",
                "trend": "crescente"
            }
        ]
        
        yield
        
        # Cleanup
        await self.redis_manager.clear_cache()
        await self.db_manager.close()
    
    @pytest.mark.asyncio
    async def test_distributed_transaction_rollback(self, setup_transaction_environment):
        """Testa rollback de transa√ß√µes distribu√≠das."""
        # Simula transa√ß√£o distribu√≠da entre banco de dados e cache
        
        # Fase 1: Inicia transa√ß√£o distribu√≠da
        transaction_id = f"trans_{int(time.time())}"
        
        try:
            # Opera√ß√£o 1: Salva no banco de dados
            db_result = await self.db_manager.save_keyword_analysis({
                "keyword": "teste-transacao-distribuida",
                "volume": 1000,
                "difficulty": 0.5,
                "cpc": 2.0,
                "transaction_id": transaction_id
            })
            
            # Opera√ß√£o 2: Salva no cache
            cache_result = await self.redis_manager.set_keyword_cache(
                f"analysis_{transaction_id}",
                {
                    "keyword": "teste-transacao-distribuida",
                    "volume": 1000,
                    "difficulty": 0.5,
                    "cpc": 2.0,
                    "transaction_id": transaction_id
                }
            )
            
            # Opera√ß√£o 3: Registra m√©trica de performance
            metric_result = await self.performance_monitor.record_metric(
                "distributed_transaction",
                {
                    "transaction_id": transaction_id,
                    "status": "success",
                    "timestamp": time.time()
                }
            )
            
            # Simula falha na opera√ß√£o 4 (for√ßa rollback)
            raise Exception("Falha simulada para testar rollback")
            
        except Exception as e:
            # Fase 2: Rollback da transa√ß√£o distribu√≠da
            
            # Rollback 1: Remove do banco de dados
            try:
                await self.db_manager.delete_keyword_analysis(transaction_id)
            except Exception:
                pass  # Ignora erros no rollback
            
            # Rollback 2: Remove do cache
            try:
                await self.redis_manager.delete_keyword_cache(f"analysis_{transaction_id}")
            except Exception:
                pass  # Ignora erros no rollback
            
            # Rollback 3: Remove m√©trica
            try:
                await self.performance_monitor.delete_metric("distributed_transaction", transaction_id)
            except Exception:
                pass  # Ignora erros no rollback
        
        # Fase 3: Verifica se o rollback foi bem-sucedido
        # Verifica se os dados foram removidos do banco
        db_check = await self.db_manager.get_keyword_analysis(transaction_id)
        assert db_check is None, "Dados n√£o foram removidos do banco ap√≥s rollback"
        
        # Verifica se os dados foram removidos do cache
        cache_check = await self.redis_manager.get_keyword_cache(f"analysis_{transaction_id}")
        assert cache_check is None, "Dados n√£o foram removidos do cache ap√≥s rollback"
    
    @pytest.mark.asyncio
    async def test_database_consistency_under_failure(self, setup_transaction_environment):
        """Testa consist√™ncia de dados sob falhas."""
        # Simula cen√°rio onde o banco falha durante opera√ß√µes
        
        consistency_checks = []
        
        for i, analysis_data in enumerate(self.test_analysis_data):
            transaction_id = f"consistency_test_{i}_{int(time.time())}"
            
            try:
                # Opera√ß√£o 1: Salva an√°lise no banco
                db_result = await self.db_manager.save_keyword_analysis({
                    **analysis_data,
                    "transaction_id": transaction_id
                })
                
                # Opera√ß√£o 2: Salva no cache
                cache_result = await self.redis_manager.set_keyword_cache(
                    f"analysis_{transaction_id}",
                    {
                        **analysis_data,
                        "transaction_id": transaction_id
                    }
                )
                
                # Verifica consist√™ncia imediata
                db_data = await self.db_manager.get_keyword_analysis(transaction_id)
                cache_data = await self.redis_manager.get_keyword_cache(f"analysis_{transaction_id}")
                
                consistency_check = {
                    "transaction_id": transaction_id,
                    "db_consistent": db_data is not None,
                    "cache_consistent": cache_data is not None,
                    "data_match": db_data == cache_data if db_data and cache_data else False
                }
                
                consistency_checks.append(consistency_check)
                
            except Exception as e:
                # Registra falha de consist√™ncia
                consistency_check = {
                    "transaction_id": transaction_id,
                    "db_consistent": False,
                    "cache_consistent": False,
                    "data_match": False,
                    "error": str(e)
                }
                consistency_checks.append(consistency_check)
        
        # Verifica consist√™ncia geral
        successful_checks = [c for c in consistency_checks if c["db_consistent"] and c["cache_consistent"]]
        consistency_rate = len(successful_checks) / len(consistency_checks)
        
        assert consistency_rate >= 0.8, f"Taxa de consist√™ncia muito baixa: {consistency_rate*100}%"
        
        # Verifica se os dados que foram salvos est√£o consistentes
        for check in successful_checks:
            assert check["data_match"], f"Dados inconsistentes para transa√ß√£o {check['transaction_id']}"
    
    @pytest.mark.asyncio
    async def test_concurrent_transaction_isolation(self, setup_transaction_environment):
        """Testa isolamento de transa√ß√µes concorrentes."""
        # Simula m√∫ltiplas transa√ß√µes simult√¢neas
        
        concurrent_transactions = 50
        transaction_results = []
        
        async def execute_transaction(transaction_id: str):
            """Executa uma transa√ß√£o isolada."""
            try:
                # Inicia transa√ß√£o
                analysis_data = {
                    "keyword": f"concurrent-test-{transaction_id}",
                    "volume": 1000 + int(transaction_id),
                    "difficulty": 0.5,
                    "cpc": 2.0,
                    "transaction_id": transaction_id
                }
                
                # Salva no banco
                db_result = await self.db_manager.save_keyword_analysis(analysis_data)
                
                # Salva no cache
                cache_result = await self.redis_manager.set_keyword_cache(
                    f"analysis_{transaction_id}",
                    analysis_data
                )
                
                # Verifica isolamento
                db_data = await self.db_manager.get_keyword_analysis(transaction_id)
                cache_data = await self.redis_manager.get_keyword_cache(f"analysis_{transaction_id}")
                
                return {
                    "transaction_id": transaction_id,
                    "success": True,
                    "db_isolated": db_data is not None,
                    "cache_isolated": cache_data is not None,
                    "data_consistent": db_data == cache_data if db_data and cache_data else False
                }
                
            except Exception as e:
                return {
                    "transaction_id": transaction_id,
                    "success": False,
                    "error": str(e)
                }
        
        # Executa transa√ß√µes simult√¢neas
        tasks = [execute_transaction(f"trans_{i}") for i in range(concurrent_transactions)]
        results = await asyncio.gather(*tasks)
        
        # Verifica isolamento das transa√ß√µes
        successful_transactions = [r for r in results if r["success"]]
        isolation_rate = len(successful_transactions) / len(results)
        
        assert isolation_rate >= 0.9, f"Taxa de isolamento muito baixa: {isolation_rate*100}%"
        
        # Verifica se cada transa√ß√£o foi isolada corretamente
        for result in successful_transactions:
            assert result["db_isolated"], f"Transa√ß√£o {result['transaction_id']} n√£o isolada no banco"
            assert result["cache_isolated"], f"Transa√ß√£o {result['transaction_id']} n√£o isolada no cache"
            assert result["data_consistent"], f"Transa√ß√£o {result['transaction_id']} com dados inconsistentes"
    
    @pytest.mark.asyncio
    async def test_transaction_rollback_on_validation_failure(self, setup_transaction_environment):
        """Testa rollback de transa√ß√£o quando valida√ß√£o falha."""
        # Simula cen√°rio onde valida√ß√£o falha durante transa√ß√£o
        
        invalid_data_sets = [
            {
                "keyword": "",  # Keyword vazia
                "volume": -1000,  # Volume negativo
                "difficulty": 1.5,  # Difficulty > 1
                "cpc": -2.0  # CPC negativo
            },
            {
                "keyword": None,  # Keyword None
                "volume": "invalid",  # Volume inv√°lido
                "difficulty": "invalid",  # Difficulty inv√°lido
                "cpc": "invalid"  # CPC inv√°lido
            },
            {
                # Dados incompletos
                "keyword": "teste-incompleto"
                # Faltam campos obrigat√≥rios
            }
        ]
        
        rollback_successes = 0
        
        for i, invalid_data in enumerate(invalid_data_sets):
            transaction_id = f"validation_rollback_{i}_{int(time.time())}"
            
            try:
                # Tenta salvar dados inv√°lidos
                db_result = await self.db_manager.save_keyword_analysis({
                    **invalid_data,
                    "transaction_id": transaction_id
                })
                
                # Se chegou aqui, deveria ter falhado na valida√ß√£o
                # For√ßa rollback manual
                await self.db_manager.delete_keyword_analysis(transaction_id)
                rollback_successes += 1
                
            except Exception as e:
                # Valida√ß√£o falhou como esperado
                # Verifica se n√£o h√° dados residuais
                db_check = await self.db_manager.get_keyword_analysis(transaction_id)
                if db_check is None:
                    rollback_successes += 1
        
        # Verifica se todos os rollbacks foram bem-sucedidos
        rollback_rate = rollback_successes / len(invalid_data_sets)
        assert rollback_rate == 1.0, f"Taxa de rollback insuficiente: {rollback_rate*100}%"
    
    @pytest.mark.asyncio
    async def test_transaction_consistency_across_services(self, setup_transaction_environment):
        """Testa consist√™ncia de transa√ß√µes entre diferentes servi√ßos."""
        # Simula transa√ß√£o que envolve m√∫ltiplos servi√ßos
        
        service_transactions = []
        
        for i, keyword in enumerate(self.test_keywords):
            transaction_id = f"service_consistency_{i}_{int(time.time())}"
            
            try:
                # Servi√ßo 1: An√°lise de keyword
                analysis_result = await self.keyword_analyzer.analyze_keyword(keyword)
                
                # Servi√ßo 2: Salva no banco
                db_result = await self.db_manager.save_keyword_analysis({
                    "keyword": keyword,
                    "analysis_result": analysis_result,
                    "transaction_id": transaction_id
                })
                
                # Servi√ßo 3: Salva no cache
                cache_result = await self.redis_manager.set_keyword_cache(
                    f"analysis_{transaction_id}",
                    {
                        "keyword": keyword,
                        "analysis_result": analysis_result,
                        "transaction_id": transaction_id
                    }
                )
                
                # Servi√ßo 4: Registra m√©trica
                metric_result = await self.performance_monitor.record_metric(
                    "keyword_analysis",
                    {
                        "keyword": keyword,
                        "transaction_id": transaction_id,
                        "timestamp": time.time()
                    }
                )
                
                # Verifica consist√™ncia entre servi√ßos
                db_data = await self.db_manager.get_keyword_analysis(transaction_id)
                cache_data = await self.redis_manager.get_keyword_cache(f"analysis_{transaction_id}")
                
                service_consistency = {
                    "transaction_id": transaction_id,
                    "keyword": keyword,
                    "analysis_success": analysis_result is not None,
                    "db_success": db_data is not None,
                    "cache_success": cache_data is not None,
                    "metric_success": metric_result is not None,
                    "all_services_consistent": all([
                        analysis_result is not None,
                        db_data is not None,
                        cache_data is not None,
                        metric_result is not None
                    ])
                }
                
                service_transactions.append(service_consistency)
                
            except Exception as e:
                # Registra falha de consist√™ncia entre servi√ßos
                service_consistency = {
                    "transaction_id": transaction_id,
                    "keyword": keyword,
                    "analysis_success": False,
                    "db_success": False,
                    "cache_success": False,
                    "metric_success": False,
                    "all_services_consistent": False,
                    "error": str(e)
                }
                service_transactions.append(service_consistency)
        
        # Verifica consist√™ncia entre servi√ßos
        consistent_transactions = [t for t in service_transactions if t["all_services_consistent"]]
        consistency_rate = len(consistent_transactions) / len(service_transactions)
        
        assert consistency_rate >= 0.8, f"Consist√™ncia entre servi√ßos muito baixa: {consistency_rate*100}%"
        
        # Verifica se pelo menos um servi√ßo funcionou em cada transa√ß√£o
        for transaction in service_transactions:
            service_successes = sum([
                transaction["analysis_success"],
                transaction["db_success"],
                transaction["cache_success"],
                transaction["metric_success"]
            ])
            assert service_successes > 0, f"Nenhum servi√ßo funcionou para transa√ß√£o {transaction['transaction_id']}" 