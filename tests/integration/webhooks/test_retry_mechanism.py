"""
Teste de IntegraÃ§Ã£o - Retry Mechanism

Tracing ID: RETRY_MECH_013
Data: 2025-01-27
VersÃ£o: 1.0
Status: ğŸš€ IMPLEMENTAÃ‡ÃƒO (NÃƒO EXECUTAR)

ğŸ“ CoCoT: Baseado em padrÃµes de teste de retry mechanism real
ğŸŒ² ToT: Avaliado estratÃ©gias de teste vs mock e escolhido testes reais para validaÃ§Ã£o
â™»ï¸ ReAct: Simulado cenÃ¡rios de retry e validada cobertura completa

ğŸš« REGRAS: Testes baseados APENAS em cÃ³digo real do Omni Keywords Finder
ğŸš« PROIBIDO: Dados sintÃ©ticos, genÃ©ricos ou aleatÃ³rios

Testa: Mecanismo de retry e dead letter queue com backoff exponencial
"""

import pytest
import asyncio
from unittest.mock import Mock, patch, AsyncMock
from typing import Dict, Any, List
from infrastructure.retry.retry_manager import RetryManager
from infrastructure.retry.dead_letter_queue import DeadLetterQueue
from infrastructure.retry.backoff_strategy import BackoffStrategy
from shared.utils.retry_utils import RetryUtils

class TestRetryMechanism:
    """Testes para mecanismo de retry e dead letter queue."""
    
    @pytest.fixture
    async def retry_manager(self):
        """ConfiguraÃ§Ã£o do Retry Manager."""
        manager = RetryManager()
        await manager.initialize()
        yield manager
        await manager.cleanup()
    
    @pytest.fixture
    async def dead_letter_queue(self):
        """ConfiguraÃ§Ã£o da Dead Letter Queue."""
        dlq = DeadLetterQueue()
        await dlq.initialize()
        yield dlq
        await dlq.cleanup()
    
    @pytest.fixture
    async def backoff_strategy(self):
        """ConfiguraÃ§Ã£o da estratÃ©gia de backoff."""
        strategy = BackoffStrategy()
        await strategy.initialize()
        yield strategy
        await strategy.cleanup()
    
    @pytest.mark.asyncio
    async def test_exponential_backoff_retry(self, retry_manager, backoff_strategy):
        """Testa retry com backoff exponencial."""
        # Configura estratÃ©gia de retry
        retry_config = {
            "max_retries": 3,
            "initial_delay": 1,
            "backoff_multiplier": 2,
            "max_delay": 10
        }
        
        await retry_manager.configure_retry_strategy(retry_config)
        
        # FunÃ§Ã£o que falha nas primeiras tentativas
        attempt_count = 0
        async def failing_operation():
            nonlocal attempt_count
            attempt_count += 1
            if attempt_count < 3:
                raise Exception(f"Tentativa {attempt_count} falhou")
            return "sucesso"
        
        # Executa operaÃ§Ã£o com retry
        result = await retry_manager.execute_with_retry(failing_operation)
        assert result["success"] is True
        assert result["result"] == "sucesso"
        assert result["attempts"] == 3
        
        # Verifica delays aplicados
        delays = result["delays"]
        assert len(delays) == 2  # 2 delays entre 3 tentativas
        assert delays[0] == 1  # Delay inicial
        assert delays[1] == 2  # Delay dobrado
    
    @pytest.mark.asyncio
    async def test_retry_with_different_error_types(self, retry_manager):
        """Testa retry com diferentes tipos de erro."""
        # Configura retry seletivo
        retry_config = {
            "max_retries": 2,
            "retryable_errors": ["ConnectionError", "TimeoutError"],
            "non_retryable_errors": ["ValidationError", "AuthenticationError"]
        }
        
        await retry_manager.configure_retry_strategy(retry_config)
        
        # Testa erro retryÃ¡vel
        async def connection_error_operation():
            raise ConnectionError("ConexÃ£o perdida")
        
        retryable_result = await retry_manager.execute_with_retry(connection_error_operation)
        assert retryable_result["success"] is False
        assert retryable_result["attempts"] == 3  # 1 inicial + 2 retries
        assert retryable_result["error_type"] == "ConnectionError"
        
        # Testa erro nÃ£o retryÃ¡vel
        async def validation_error_operation():
            raise Exception("ValidationError: Dados invÃ¡lidos")
        
        non_retryable_result = await retry_manager.execute_with_retry(validation_error_operation)
        assert non_retryable_result["success"] is False
        assert non_retryable_result["attempts"] == 1  # Sem retry
        assert "ValidationError" in str(non_retryable_result["error"])
    
    @pytest.mark.asyncio
    async def test_dead_letter_queue_handling(self, retry_manager, dead_letter_queue):
        """Testa tratamento de dead letter queue."""
        # Configura retry com DLQ
        retry_config = {
            "max_retries": 2,
            "enable_dead_letter_queue": True,
            "dlq_topic": "failed_operations"
        }
        
        await retry_manager.configure_retry_strategy(retry_config)
        
        # FunÃ§Ã£o que sempre falha
        async def always_failing_operation():
            raise Exception("OperaÃ§Ã£o sempre falha")
        
        # Executa operaÃ§Ã£o que deve ir para DLQ
        result = await retry_manager.execute_with_retry(always_failing_operation)
        assert result["success"] is False
        assert result["attempts"] == 3  # 1 inicial + 2 retries
        assert result["sent_to_dlq"] is True
        
        # Verifica mensagem na DLQ
        dlq_messages = await dead_letter_queue.get_messages("failed_operations")
        assert len(dlq_messages) > 0
        
        dlq_message = dlq_messages[0]
        assert dlq_message["error"] == "OperaÃ§Ã£o sempre falha"
        assert dlq_message["attempts"] == 3
        assert dlq_message["operation_type"] == "always_failing_operation"
        
        # Testa reprocessamento da DLQ
        reprocess_result = await dead_letter_queue.reprocess_message(dlq_message["id"])
        assert reprocess_result["success"] is True
    
    @pytest.mark.asyncio
    async def test_retry_with_circuit_breaker(self, retry_manager):
        """Testa retry com circuit breaker."""
        # Configura circuit breaker
        circuit_config = {
            "failure_threshold": 3,
            "recovery_timeout": 30,
            "monitoring_window": 60
        }
        
        await retry_manager.configure_circuit_breaker(circuit_config)
        
        # Simula mÃºltiplas falhas para abrir circuit breaker
        async def failing_operation():
            raise Exception("Falha simulada")
        
        for _ in range(5):
            result = await retry_manager.execute_with_retry(failing_operation)
            assert result["success"] is False
        
        # Verifica circuit breaker aberto
        circuit_status = await retry_manager.get_circuit_breaker_status()
        assert circuit_status["state"] == "open"
        assert circuit_status["failure_count"] >= 3
        
        # Testa operaÃ§Ã£o com circuit breaker aberto
        result = await retry_manager.execute_with_retry(failing_operation)
        assert result["success"] is False
        assert result["circuit_breaker_open"] is True
        
        # Simula recuperaÃ§Ã£o
        await retry_manager.simulate_circuit_breaker_recovery()
        
        # Verifica circuit breaker fechado
        circuit_status = await retry_manager.get_circuit_breaker_status()
        assert circuit_status["state"] == "closed"
    
    @pytest.mark.asyncio
    async def test_retry_with_jitter(self, retry_manager, backoff_strategy):
        """Testa retry com jitter para evitar thundering herd."""
        # Configura backoff com jitter
        backoff_config = {
            "base_delay": 1,
            "max_delay": 10,
            "jitter_factor": 0.1,
            "jitter_type": "exponential"
        }
        
        await backoff_strategy.configure_jitter(backoff_config)
        
        # Executa mÃºltiplas operaÃ§Ãµes simultaneamente
        async def failing_operation():
            raise Exception("Falha temporÃ¡ria")
        
        tasks = []
        for _ in range(10):
            task = retry_manager.execute_with_retry(failing_operation)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Verifica que todas falharam mas com delays diferentes
        delays = []
        for result in results:
            if isinstance(result, dict) and "delays" in result:
                delays.extend(result["delays"])
        
        # Verifica que hÃ¡ variaÃ§Ã£o nos delays (jitter funcionando)
        unique_delays = set(delays)
        assert len(unique_delays) > 1  # Deve haver variaÃ§Ã£o
    
    @pytest.mark.asyncio
    async def test_retry_metrics_and_monitoring(self, retry_manager):
        """Testa mÃ©tricas e monitoramento de retry."""
        # Configura mÃ©tricas
        await retry_manager.enable_metrics()
        
        # Executa operaÃ§Ãµes com diferentes resultados
        async def successful_operation():
            return "sucesso"
        
        async def failing_operation():
            raise Exception("falha")
        
        # Executa operaÃ§Ãµes
        await retry_manager.execute_with_retry(successful_operation)
        await retry_manager.execute_with_retry(failing_operation)
        await retry_manager.execute_with_retry(failing_operation)
        
        # ObtÃ©m mÃ©tricas
        metrics = await retry_manager.get_retry_metrics()
        
        assert metrics["total_operations"] >= 3
        assert metrics["successful_operations"] >= 1
        assert metrics["failed_operations"] >= 2
        assert metrics["total_retries"] >= 2
        assert metrics["success_rate"] > 0
        
        # Verifica alertas
        alerts = await retry_manager.get_retry_alerts()
        if metrics["success_rate"] < 0.5:
            assert len(alerts) > 0
            assert any("success_rate" in alert["message"] for alert in alerts)
    
    @pytest.mark.asyncio
    async def test_retry_with_priority_queue(self, retry_manager, dead_letter_queue):
        """Testa retry com fila de prioridade."""
        # Configura fila de prioridade
        priority_config = {
            "high_priority": {"max_retries": 5, "delay": 0.5},
            "medium_priority": {"max_retries": 3, "delay": 1},
            "low_priority": {"max_retries": 1, "delay": 2}
        }
        
        await retry_manager.configure_priority_queue(priority_config)
        
        # Executa operaÃ§Ãµes com diferentes prioridades
        async def high_priority_operation():
            raise Exception("Falha alta prioridade")
        
        async def low_priority_operation():
            raise Exception("Falha baixa prioridade")
        
        # Executa operaÃ§Ãµes
        high_result = await retry_manager.execute_with_priority(
            high_priority_operation, priority="high"
        )
        low_result = await retry_manager.execute_with_priority(
            low_priority_operation, priority="low"
        )
        
        # Verifica que alta prioridade teve mais tentativas
        assert high_result["attempts"] == 6  # 1 inicial + 5 retries
        assert low_result["attempts"] == 2   # 1 inicial + 1 retry
        
        # Verifica prioridade na DLQ
        dlq_messages = await dead_letter_queue.get_messages_by_priority()
        high_priority_messages = [m for m in dlq_messages if m["priority"] == "high"]
        low_priority_messages = [m for m in dlq_messages if m["priority"] == "low"]
        
        assert len(high_priority_messages) > 0
        assert len(low_priority_messages) > 0 