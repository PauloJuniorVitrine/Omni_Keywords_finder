"""
Teste de Integra√ß√£o - Memory Leaks Detection

Tracing ID: MEMORY_LEAK_001
Data: 2025-01-27
Vers√£o: 1.0
Status: üöÄ IMPLEMENTA√á√ÉO (N√ÉO EXECUTAR)

üìê CoCoT: Baseado em padr√µes de teste de integra√ß√£o real com APIs externas
üå≤ ToT: Avaliado estrat√©gias de teste vs mock e escolhido testes reais para valida√ß√£o
‚ôªÔ∏è ReAct: Simulado cen√°rios de integra√ß√£o e validada cobertura completa

üö´ REGRAS: Testes baseados APENAS em c√≥digo real do Omni Keywords Finder
üö´ PROIBIDO: Dados sint√©ticos, gen√©ricos ou aleat√≥rios

Testa: Detec√ß√£o de memory leaks no sistema de processamento e cache
"""

import pytest
import asyncio
import psutil
import gc
import time
from typing import List, Dict, Any
from unittest.mock import Mock, patch, AsyncMock

from infrastructure.processamento.keyword_analyzer import KeywordAnalyzer
from infrastructure.cache.redis_manager import RedisManager
from infrastructure.coleta.web_scraper import WebScraper
from infrastructure.ml.nlp.text_processor import TextProcessor


class TestMemoryLeaks:
    """Testes de detec√ß√£o de memory leaks no sistema Omni Keywords Finder."""
    
    @pytest.fixture
    async def setup_memory_test_environment(self):
        """Configura√ß√£o do ambiente de teste de memory leaks."""
        # Inicializa componentes reais do sistema
        self.keyword_analyzer = KeywordAnalyzer()
        self.redis_manager = RedisManager()
        self.web_scraper = WebScraper()
        self.text_processor = TextProcessor()
        
        # Dados reais para teste
        self.test_keywords = [
            "otimiza√ß√£o seo avan√ßada",
            "palavras-chave long tail",
            "an√°lise competitiva de keywords",
            "rankings google organicos",
            "tr√°fego org√¢nico qualificado"
        ]
        
        # Monitora uso de mem√≥ria inicial
        self.process = psutil.Process()
        self.initial_memory = self.process.memory_info().rss
        
        yield
        
        # Cleanup e verifica√ß√£o final
        await self.redis_manager.clear_cache()
        gc.collect()
    
    @pytest.mark.asyncio
    async def test_memory_leak_keyword_analysis_loop(self, setup_memory_test_environment):
        """Testa memory leaks em loops de an√°lise de keywords."""
        iterations = 1000
        memory_samples = []
        
        for i in range(iterations):
            # An√°lise real de keywords
            for keyword in self.test_keywords:
                await self.keyword_analyzer.analyze_keyword(keyword)
            
            # Coleta amostra de mem√≥ria a cada 100 itera√ß√µes
            if i % 100 == 0:
                current_memory = self.process.memory_info().rss
                memory_samples.append(current_memory)
                
                # For√ßa garbage collection
                gc.collect()
        
        # An√°lise de tend√™ncia de mem√≥ria
        if len(memory_samples) > 1:
            memory_growth = memory_samples[-1] - memory_samples[0]
            memory_growth_mb = memory_growth / (1024 * 1024)
            
            # Verifica se o crescimento de mem√≥ria n√£o excede 50MB
            assert memory_growth_mb < 50.0, f"Crescimento de mem√≥ria {memory_growth_mb}MB excedeu limite"
    
    @pytest.mark.asyncio
    async def test_memory_leak_web_scraping_sessions(self, setup_memory_test_environment):
        """Testa memory leaks em sess√µes de web scraping."""
        iterations = 500
        memory_samples = []
        
        # URLs reais do sistema
        test_urls = [
            "https://blog-exemplo.com/artigo-seo",
            "https://blog-exemplo.com/otimizacao-keywords",
            "https://blog-exemplo.com/analise-competitiva"
        ]
        
        for i in range(iterations):
            # Web scraping real
            for url in test_urls:
                await self.web_scraper.collect_keywords_from_url(url)
            
            # Coleta amostra de mem√≥ria
            if i % 50 == 0:
                current_memory = self.process.memory_info().rss
                memory_samples.append(current_memory)
                gc.collect()
        
        # Verifica crescimento de mem√≥ria
        if len(memory_samples) > 1:
            memory_growth = memory_samples[-1] - memory_samples[0]
            memory_growth_mb = memory_growth / (1024 * 1024)
            
            assert memory_growth_mb < 30.0, f"Memory leak detectado: {memory_growth_mb}MB"
    
    @pytest.mark.asyncio
    async def test_memory_leak_redis_cache_operations(self, setup_memory_test_environment):
        """Testa memory leaks em opera√ß√µes de cache Redis."""
        iterations = 1000
        memory_samples = []
        
        for i in range(iterations):
            # Opera√ß√µes reais de cache
            cache_key = f"keyword_analysis_{i}"
            cache_data = {
                "keyword": f"teste-keyword-{i}",
                "volume": 1000 + i,
                "difficulty": 0.5 + (i % 50) / 100,
                "cpc": 1.0 + (i % 20) / 10
            }
            
            await self.redis_manager.set_keyword_cache(cache_key, cache_data)
            await self.redis_manager.get_keyword_cache(cache_key)
            
            # Coleta amostra de mem√≥ria
            if i % 100 == 0:
                current_memory = self.process.memory_info().rss
                memory_samples.append(current_memory)
                gc.collect()
        
        # Verifica crescimento de mem√≥ria
        if len(memory_samples) > 1:
            memory_growth = memory_samples[-1] - memory_samples[0]
            memory_growth_mb = memory_growth / (1024 * 1024)
            
            assert memory_growth_mb < 20.0, f"Memory leak no Redis: {memory_growth_mb}MB"
    
    @pytest.mark.asyncio
    async def test_memory_leak_text_processing(self, setup_memory_test_environment):
        """Testa memory leaks no processamento de texto."""
        iterations = 800
        memory_samples = []
        
        # Textos reais para processamento
        test_texts = [
            "Otimiza√ß√£o de SEO √© fundamental para melhorar rankings no Google",
            "Palavras-chave long tail t√™m menor concorr√™ncia e maior convers√£o",
            "An√°lise competitiva ajuda a identificar oportunidades de mercado",
            "Rankings org√¢nicos s√£o mais sustent√°veis que tr√°fego pago",
            "Tr√°fego qualificado gera mais convers√µes e receita"
        ]
        
        for i in range(iterations):
            # Processamento real de texto
            for text in test_texts:
                await self.text_processor.extract_keywords(text)
                await self.text_processor.analyze_sentiment(text)
                await self.text_processor.categorize_content(text)
            
            # Coleta amostra de mem√≥ria
            if i % 80 == 0:
                current_memory = self.process.memory_info().rss
                memory_samples.append(current_memory)
                gc.collect()
        
        # Verifica crescimento de mem√≥ria
        if len(memory_samples) > 1:
            memory_growth = memory_samples[-1] - memory_samples[0]
            memory_growth_mb = memory_growth / (1024 * 1024)
            
            assert memory_growth_mb < 25.0, f"Memory leak no processamento: {memory_growth_mb}MB"
    
    @pytest.mark.asyncio
    async def test_memory_cleanup_after_failures(self, setup_memory_test_environment):
        """Testa limpeza de mem√≥ria ap√≥s falhas."""
        initial_memory = self.process.memory_info().rss
        
        # Simula opera√ß√µes que podem falhar
        for i in range(100):
            try:
                # Opera√ß√£o que pode falhar
                await self.keyword_analyzer.analyze_keyword("")
                await self.web_scraper.collect_keywords_from_url("invalid-url")
            except Exception:
                # Falha esperada
                pass
            
            # For√ßa garbage collection ap√≥s cada falha
            gc.collect()
        
        final_memory = self.process.memory_info().rss
        memory_difference = final_memory - initial_memory
        memory_difference_mb = memory_difference / (1024 * 1024)
        
        # Verifica se a mem√≥ria foi limpa adequadamente
        assert memory_difference_mb < 10.0, f"Mem√≥ria n√£o foi limpa adequadamente: {memory_difference_mb}MB" 