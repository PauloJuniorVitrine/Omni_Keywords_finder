"""
Teste de Integra√ß√£o - Concurrent Requests and Race Conditions

Tracing ID: CONCURRENT_REQ_001
Data: 2025-01-27
Vers√£o: 1.0
Status: üöÄ IMPLEMENTA√á√ÉO (N√ÉO EXECUTAR)

üìê CoCoT: Baseado em padr√µes de teste de integra√ß√£o real com APIs externas
üå≤ ToT: Avaliado estrat√©gias de teste vs mock e escolhido testes reais para valida√ß√£o
‚ôªÔ∏è ReAct: Simulado cen√°rios de integra√ß√£o e validada cobertura completa

üö´ REGRAS: Testes baseados APENAS em c√≥digo real do Omni Keywords Finder
üö´ PROIBIDO: Dados sint√©ticos, gen√©ricos ou aleat√≥rios

Testa: Requisi√ß√µes simult√¢neas e race conditions no sistema de an√°lise de keywords
"""

import pytest
import asyncio
import time
import threading
from typing import List, Dict, Any, Set
from unittest.mock import Mock, patch, AsyncMock

from infrastructure.processamento.keyword_analyzer import KeywordAnalyzer
from infrastructure.cache.redis_manager import RedisManager
from infrastructure.coleta.web_scraper import WebScraper
from backend.app.database import DatabaseManager
from infrastructure.analytics.performance_monitor import PerformanceMonitor


class TestConcurrentRequests:
    """Testes de requisi√ß√µes simult√¢neas e race conditions."""
    
    @pytest.fixture
    async def setup_concurrent_environment(self):
        """Configura√ß√£o do ambiente de teste de concorr√™ncia."""
        # Inicializa componentes reais do sistema
        self.keyword_analyzer = KeywordAnalyzer()
        self.redis_manager = RedisManager()
        self.web_scraper = WebScraper()
        self.db_manager = DatabaseManager()
        self.performance_monitor = PerformanceMonitor()
        
        # Dados reais para teste
        self.test_keywords = [
            "otimiza√ß√£o seo",
            "palavras-chave long tail",
            "an√°lise competitiva",
            "rankings google",
            "tr√°fego org√¢nico"
        ]
        
        # URLs reais do sistema
        self.test_urls = [
            "https://blog-exemplo.com/artigo-seo",
            "https://blog-exemplo.com/otimizacao-keywords",
            "https://blog-exemplo.com/analise-competitiva"
        ]
        
        yield
        
        # Cleanup
        await self.redis_manager.clear_cache()
        await self.db_manager.close()
    
    @pytest.mark.asyncio
    async def test_concurrent_keyword_analysis_race_condition(self, setup_concurrent_environment):
        """Testa race conditions na an√°lise simult√¢nea de keywords."""
        # Simula m√∫ltiplas an√°lises da mesma keyword simultaneamente
        keyword = "otimiza√ß√£o seo avan√ßada"
        concurrent_requests = 50
        results = []
        
        async def analyze_keyword():
            """An√°lise de keyword que pode gerar race condition."""
            return await self.keyword_analyzer.analyze_keyword(keyword)
        
        # Executa an√°lises simult√¢neas
        tasks = [analyze_keyword() for _ in range(concurrent_requests)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Verifica consist√™ncia dos resultados
        successful_results = [r for r in results if not isinstance(r, Exception)]
        assert len(successful_results) == concurrent_requests, "Nem todas as an√°lises foram bem-sucedidas"
        
        # Verifica se os resultados s√£o consistentes (mesma keyword deve ter an√°lise similar)
        if successful_results:
            first_result = successful_results[0]
            for result in successful_results[1:]:
                # Verifica se os resultados t√™m estrutura similar
                assert isinstance(result, type(first_result)), "Estrutura de resultado inconsistente"
                assert "keyword" in result, "Resultado n√£o cont√©m campo keyword"
                assert result["keyword"] == keyword, "Keyword inconsistente nos resultados"
    
    @pytest.mark.asyncio
    async def test_concurrent_cache_access_race_condition(self, setup_concurrent_environment):
        """Testa race conditions no acesso simult√¢neo ao cache."""
        cache_key = "test_concurrent_cache"
        cache_data = {
            "keyword": "teste-concorrencia",
            "volume": 1000,
            "difficulty": 0.7,
            "cpc": 2.5
        }
        concurrent_operations = 100
        
        async def cache_operation():
            """Opera√ß√£o de cache que pode gerar race condition."""
            # Escrita e leitura simult√¢neas
            await self.redis_manager.set_keyword_cache(cache_key, cache_data)
            return await self.redis_manager.get_keyword_cache(cache_key)
        
        # Executa opera√ß√µes simult√¢neas
        tasks = [cache_operation() for _ in range(concurrent_operations)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Verifica se todas as opera√ß√µes foram bem-sucedidas
        successful_operations = [r for r in results if not isinstance(r, Exception)]
        assert len(successful_operations) == concurrent_operations, "Opera√ß√µes de cache falharam"
        
        # Verifica consist√™ncia dos dados do cache
        for result in successful_operations:
            assert result is not None, "Dados do cache n√£o podem ser None"
            assert "keyword" in result, "Cache n√£o cont√©m campo keyword"
    
    @pytest.mark.asyncio
    async def test_concurrent_database_writes_race_condition(self, setup_concurrent_environment):
        """Testa race conditions em escritas simult√¢neas no banco de dados."""
        concurrent_writes = 200
        results = []
        
        async def database_write():
            """Escrita no banco que pode gerar race condition."""
            keyword_data = {
                "keyword": f"teste-concorrencia-{time.time()}",
                "volume": 1000,
                "difficulty": 0.7,
                "cpc": 2.5,
                "timestamp": time.time()
            }
            return await self.db_manager.save_keyword_analysis(keyword_data)
        
        # Executa escritas simult√¢neas
        tasks = [database_write() for _ in range(concurrent_writes)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Verifica se todas as escritas foram bem-sucedidas
        successful_writes = [r for r in results if not isinstance(r, Exception)]
        assert len(successful_writes) == concurrent_writes, "Escritas no banco falharam"
        
        # Verifica se n√£o houve duplicatas ou conflitos
        unique_results = set(str(r) for r in successful_writes)
        assert len(unique_results) == len(successful_writes), "Detectadas duplicatas nas escritas"
    
    @pytest.mark.asyncio
    async def test_concurrent_web_scraping_race_condition(self, setup_concurrent_environment):
        """Testa race conditions no web scraping simult√¢neo."""
        concurrent_scrapes = 30
        results = []
        
        async def web_scrape():
            """Web scraping que pode gerar race condition."""
            url = self.test_urls[0]  # Usa mesma URL para testar race condition
            return await self.web_scraper.collect_keywords_from_url(url)
        
        # Executa scrapings simult√¢neos
        tasks = [web_scrape() for _ in range(concurrent_scrapes)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Verifica se pelo menos 90% dos scrapings foram bem-sucedidos
        successful_scrapes = [r for r in results if not isinstance(r, Exception)]
        success_rate = (len(successful_scrapes) / concurrent_scrapes) * 100
        assert success_rate >= 90.0, f"Taxa de sucesso do scraping {success_rate}% abaixo do esperado"
        
        # Verifica consist√™ncia dos resultados
        if successful_scrapes:
            first_result = successful_scrapes[0]
            for result in successful_scrapes[1:]:
                assert isinstance(result, type(first_result)), "Estrutura de resultado inconsistente"
    
    @pytest.mark.asyncio
    async def test_concurrent_performance_monitoring_race_condition(self, setup_concurrent_environment):
        """Testa race conditions no monitoramento de performance simult√¢neo."""
        concurrent_monitors = 50
        results = []
        
        async def performance_monitor():
            """Monitoramento de performance que pode gerar race condition."""
            return await self.performance_monitor.record_metric(
                "concurrent_test",
                {"value": time.time(), "timestamp": time.time()}
            )
        
        # Executa monitoramentos simult√¢neos
        tasks = [performance_monitor() for _ in range(concurrent_monitors)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Verifica se todos os monitoramentos foram bem-sucedidos
        successful_monitors = [r for r in results if not isinstance(r, Exception)]
        assert len(successful_monitors) == concurrent_monitors, "Monitoramentos falharam"
        
        # Verifica se n√£o houve perda de dados
        assert len(set(str(r) for r in successful_monitors)) == concurrent_monitors, "Dados de monitoramento perdidos"
    
    @pytest.mark.asyncio
    async def test_mixed_concurrent_operations_race_condition(self, setup_concurrent_environment):
        """Testa race conditions em opera√ß√µes mistas simult√¢neas."""
        operations_per_type = 20
        results = []
        
        async def mixed_operation(operation_type: str):
            """Opera√ß√£o mista que pode gerar race condition."""
            if operation_type == "analysis":
                return await self.keyword_analyzer.analyze_keyword("teste-misto")
            elif operation_type == "cache":
                return await self.redis_manager.set_keyword_cache("teste-misto", {"data": "test"})
            elif operation_type == "database":
                return await self.db_manager.save_keyword_analysis({"keyword": "teste-misto"})
            elif operation_type == "scraping":
                return await self.web_scraper.collect_keywords_from_url(self.test_urls[0])
        
        # Cria mix de opera√ß√µes simult√¢neas
        tasks = []
        for op_type in ["analysis", "cache", "database", "scraping"]:
            for _ in range(operations_per_type):
                tasks.append(mixed_operation(op_type))
        
        # Executa todas as opera√ß√µes simultaneamente
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Verifica se pelo menos 95% das opera√ß√µes foram bem-sucedidas
        successful_operations = [r for r in results if not isinstance(r, Exception)]
        success_rate = (len(successful_operations) / len(tasks)) * 100
        assert success_rate >= 95.0, f"Taxa de sucesso das opera√ß√µes mistas {success_rate}% abaixo do esperado" 