#!/usr/bin/env python3
"""
üéØ MAPEAMENTO DE FUNCIONALIDADES CR√çTICAS - OMNƒ∞ KEYWORDS FINDER
üìê CoCoT: Comprova√ß√£o, Causalidade, Contexto, Tend√™ncia
üå≤ ToT: M√∫ltiplas abordagens de an√°lise
‚ôªÔ∏è ReAct: Simula√ß√£o e reflex√£o sobre impactos
üñºÔ∏è Visual: Representa√ß√µes de relacionamentos

Tracing ID: CRITICAL_FEATURES_MAPPER_20250127_001
Data: 2025-01-27
Vers√£o: 1.0.0
Status: ‚úÖ CRIA√á√ÉO DE SCRIPT
"""

import os
import sys
import json
import ast
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional, NamedTuple
from dataclasses import dataclass, field
from datetime import datetime
import logging
from collections import defaultdict, Counter
import networkx as nx
import matplotlib.pyplot as plt

# Configura√ß√£o de logging estruturado
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class CriticalFeature:
    """Funcionalidade cr√≠tica identificada"""
    name: str
    type: str  # api, service, function, class, module
    file_path: str
    line_number: int
    criticality_score: float  # 0.0 a 1.0
    impact_areas: List[str]  # performance, security, availability, data_integrity
    dependencies: List[str]
    dependents: List[str]
    complexity: int
    usage_frequency: int
    risk_level: str  # LOW, MEDIUM, HIGH, CRITICAL
    description: str = ""
    recommendations: List[str] = field(default_factory=list)

@dataclass
class CriticalFeaturesResult:
    """Resultado do mapeamento de funcionalidades cr√≠ticas"""
    total_features: int
    critical_features: int
    high_risk_features: int
    critical_apis: int
    critical_services: int
    critical_functions: int
    critical_classes: int
    dependency_graph: Dict[str, List[str]]
    impact_analysis: Dict[str, Dict[str, float]]
    recommendations: List[str]
    risk_assessment: Dict[str, int]
    critical_paths: List[List[str]]

class CriticalFeaturesMapper:
    """
    üìê CoCoT - Mapeador de Funcionalidades Cr√≠ticas Avan√ßado
    
    Comprova√ß√£o: Baseado em an√°lise de depend√™ncias e impacto
    Causalidade: Identifica funcionalidades essenciais
    Contexto: Considera arquitetura e padr√µes do projeto
    Tend√™ncia: Aplica t√©cnicas modernas de an√°lise de sistemas
    """
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.features: Dict[str, CriticalFeature] = {}
        self.dependency_graph = nx.DiGraph()
        self.usage_patterns: Dict[str, int] = Counter()
        self.impact_scores: Dict[str, float] = {}
        
        # Padr√µes de funcionalidades cr√≠ticas
        self.critical_patterns = {
            "api": [
                r'@app\.route',
                r'@api\.',
                r'@router\.',
                r'def.*_api',
                r'class.*API',
                r'class.*Controller'
            ],
            "service": [
                r'class.*Service',
                r'class.*Manager',
                r'class.*Handler',
                r'def.*_service',
                r'def.*_manager'
            ],
            "database": [
                r'class.*Model',
                r'class.*Repository',
                r'def.*_query',
                r'def.*_save',
                r'def.*_delete',
                r'def.*_update'
            ],
            "security": [
                r'def.*_auth',
                r'def.*_login',
                r'def.*_logout',
                r'def.*_validate',
                r'class.*Auth',
                r'class.*Security'
            ],
            "core": [
                r'def.*main',
                r'def.*run',
                r'def.*start',
                r'def.*init',
                r'class.*Core',
                r'class.*Engine'
            ]
        }
        
        # Padr√µes de exclus√£o
        self.exclude_patterns = [
            r'__init__\.py$',
            r'__pycache__',
            r'\.pyc$',
            r'\.git',
            r'node_modules',
            r'\.venv',
            r'tests?/',
            r'docs/',
            r'logs/',
            r'\.env'
        ]
    
    def map_critical_features(self) -> CriticalFeaturesResult:
        """
        üå≤ ToT - Mapeamento Completo de Funcionalidades Cr√≠ticas
        
        Abordagem 1: An√°lise de depend√™ncias (ESCOLHIDA)
        Abordagem 2: An√°lise de performance
        Abordagem 3: An√°lise de neg√≥cio
        """
        logger.info("üîç Iniciando mapeamento de funcionalidades cr√≠ticas...")
        
        # Etapa 1: Scan de arquivos Python
        python_files = self._get_python_files()
        logger.info(f"üìÅ Encontrados {len(python_files)} arquivos Python")
        
        # Etapa 2: Identifica√ß√£o de funcionalidades cr√≠ticas
        for file_path in python_files:
            try:
                self._analyze_file_critical_features(file_path)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao analisar {file_path}: {e}")
        
        # Etapa 3: An√°lise de depend√™ncias
        self._analyze_dependencies()
        
        # Etapa 4: C√°lculo de scores de criticidade
        self._calculate_criticality_scores()
        
        # Etapa 5: Identifica√ß√£o de caminhos cr√≠ticos
        critical_paths = self._identify_critical_paths()
        
        # Etapa 6: Gera√ß√£o de resultado
        result = self._generate_mapping_result(critical_paths)
        
        logger.info(f"‚úÖ Mapeamento conclu√≠do. {len(self.features)} funcionalidades cr√≠ticas identificadas")
        return result
    
    def _get_python_files(self) -> List[Path]:
        """Obt√©m lista de arquivos Python para an√°lise"""
        python_files = []
        
        for file_path in self.project_root.rglob("*.py"):
            # Verificar padr√µes de exclus√£o
            if any(re.search(pattern, str(file_path)) for pattern in self.exclude_patterns):
                continue
            
            python_files.append(file_path)
        
        return python_files
    
    def _analyze_file_critical_features(self, file_path: Path):
        """
        ‚ôªÔ∏è ReAct - An√°lise de Funcionalidades Cr√≠ticas por Arquivo
        
        Simula√ß√£o: Identifica√ß√£o de padr√µes cr√≠ticos
        Efeitos: Mapeamento de funcionalidades essenciais
        Ganhos: Visibilidade completa do sistema
        Riscos: Falsos positivos (mitig√°vel com valida√ß√£o)
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Parse AST
            tree = ast.parse(content)
            
            # Analisar diferentes tipos de funcionalidades cr√≠ticas
            self._analyze_critical_apis(tree, file_path)
            self._analyze_critical_services(tree, file_path)
            self._analyze_critical_functions(tree, file_path)
            self._analyze_critical_classes(tree, file_path)
            self._analyze_critical_modules(tree, file_path)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao analisar AST de {file_path}: {e}")
    
    def _analyze_critical_apis(self, tree: ast.AST, file_path: Path):
        """An√°lise de APIs cr√≠ticas"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # Verificar se √© API
                if any(re.search(pattern, node.name) for pattern in self.critical_patterns["api"]):
                    feature = CriticalFeature(
                        name=node.name,
                        type="api",
                        file_path=str(file_path),
                        line_number=node.lineno,
                        criticality_score=0.0,  # Ser√° calculado depois
                        impact_areas=["availability", "performance"],
                        dependencies=[],
                        dependents=[],
                        complexity=self._calculate_complexity(node),
                        usage_frequency=0,
                        risk_level="HIGH",
                        description=f"API endpoint: {node.name}"
                    )
                    self.features[f"api:{node.name}:{file_path}"] = feature
                    self.dependency_graph.add_node(f"api:{node.name}:{file_path}")
            
            elif isinstance(node, ast.ClassDef):
                # Verificar se √© classe de API
                if any(re.search(pattern, node.name) for pattern in self.critical_patterns["api"]):
                    feature = CriticalFeature(
                        name=node.name,
                        type="api",
                        file_path=str(file_path),
                        line_number=node.lineno,
                        criticality_score=0.0,
                        impact_areas=["availability", "performance"],
                        dependencies=[],
                        dependents=[],
                        complexity=self._calculate_complexity(node),
                        usage_frequency=0,
                        risk_level="HIGH",
                        description=f"API class: {node.name}"
                    )
                    self.features[f"api:{node.name}:{file_path}"] = feature
                    self.dependency_graph.add_node(f"api:{node.name}:{file_path}")
    
    def _analyze_critical_services(self, tree: ast.AST, file_path: Path):
        """An√°lise de servi√ßos cr√≠ticos"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # Verificar se √© servi√ßo
                if any(re.search(pattern, node.name) for pattern in self.critical_patterns["service"]):
                    feature = CriticalFeature(
                        name=node.name,
                        type="service",
                        file_path=str(file_path),
                        line_number=node.lineno,
                        criticality_score=0.0,
                        impact_areas=["availability", "data_integrity"],
                        dependencies=[],
                        dependents=[],
                        complexity=self._calculate_complexity(node),
                        usage_frequency=0,
                        risk_level="HIGH",
                        description=f"Service: {node.name}"
                    )
                    self.features[f"service:{node.name}:{file_path}"] = feature
                    self.dependency_graph.add_node(f"service:{node.name}:{file_path}")
    
    def _analyze_critical_functions(self, tree: ast.AST, file_path: Path):
        """An√°lise de fun√ß√µes cr√≠ticas"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # Verificar se √© fun√ß√£o cr√≠tica
                critical_patterns = (
                    self.critical_patterns["database"] +
                    self.critical_patterns["security"] +
                    self.critical_patterns["core"]
                )
                
                if any(re.search(pattern, node.name) for pattern in critical_patterns):
                    # Determinar tipo e √°reas de impacto
                    feature_type = "function"
                    impact_areas = ["performance"]
                    
                    if any(re.search(pattern, node.name) for pattern in self.critical_patterns["database"]):
                        feature_type = "database"
                        impact_areas = ["data_integrity", "performance"]
                    elif any(re.search(pattern, node.name) for pattern in self.critical_patterns["security"]):
                        feature_type = "security"
                        impact_areas = ["security", "availability"]
                    elif any(re.search(pattern, node.name) for pattern in self.critical_patterns["core"]):
                        feature_type = "core"
                        impact_areas = ["availability", "performance"]
                    
                    feature = CriticalFeature(
                        name=node.name,
                        type=feature_type,
                        file_path=str(file_path),
                        line_number=node.lineno,
                        criticality_score=0.0,
                        impact_areas=impact_areas,
                        dependencies=[],
                        dependents=[],
                        complexity=self._calculate_complexity(node),
                        usage_frequency=0,
                        risk_level="MEDIUM",
                        description=f"Critical function: {node.name}"
                    )
                    self.features[f"{feature_type}:{node.name}:{file_path}"] = feature
                    self.dependency_graph.add_node(f"{feature_type}:{node.name}:{file_path}")
    
    def _analyze_critical_classes(self, tree: ast.AST, file_path: Path):
        """An√°lise de classes cr√≠ticas"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                # Verificar se √© classe cr√≠tica
                critical_patterns = (
                    self.critical_patterns["database"] +
                    self.critical_patterns["security"] +
                    self.critical_patterns["core"]
                )
                
                if any(re.search(pattern, node.name) for pattern in critical_patterns):
                    # Determinar tipo e √°reas de impacto
                    feature_type = "class"
                    impact_areas = ["performance"]
                    
                    if any(re.search(pattern, node.name) for pattern in self.critical_patterns["database"]):
                        feature_type = "database"
                        impact_areas = ["data_integrity", "performance"]
                    elif any(re.search(pattern, node.name) for pattern in self.critical_patterns["security"]):
                        feature_type = "security"
                        impact_areas = ["security", "availability"]
                    elif any(re.search(pattern, node.name) for pattern in self.critical_patterns["core"]):
                        feature_type = "core"
                        impact_areas = ["availability", "performance"]
                    
                    feature = CriticalFeature(
                        name=node.name,
                        type=feature_type,
                        file_path=str(file_path),
                        line_number=node.lineno,
                        criticality_score=0.0,
                        impact_areas=impact_areas,
                        dependencies=[],
                        dependents=[],
                        complexity=self._calculate_complexity(node),
                        usage_frequency=0,
                        risk_level="MEDIUM",
                        description=f"Critical class: {node.name}"
                    )
                    self.features[f"{feature_type}:{node.name}:{file_path}"] = feature
                    self.dependency_graph.add_node(f"{feature_type}:{node.name}:{file_path}")
    
    def _analyze_critical_modules(self, tree: ast.AST, file_path: Path):
        """An√°lise de m√≥dulos cr√≠ticos"""
        # Verificar se o arquivo inteiro √© cr√≠tico
        file_name = file_path.name
        if any(keyword in file_name.lower() for keyword in ['main', 'core', 'engine', 'api', 'service']):
            feature = CriticalFeature(
                name=file_name,
                type="module",
                file_path=str(file_path),
                line_number=1,
                criticality_score=0.0,
                impact_areas=["availability", "performance"],
                dependencies=[],
                dependents=[],
                complexity=0,
                usage_frequency=0,
                risk_level="HIGH",
                description=f"Critical module: {file_name}"
            )
            self.features[f"module:{file_name}:{file_path}"] = feature
            self.dependency_graph.add_node(f"module:{file_name}:{file_path}")
    
    def _calculate_complexity(self, node: ast.AST) -> int:
        """Calcula complexidade ciclom√°tica"""
        complexity = 1  # Base complexity
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
            elif isinstance(child, ast.With):
                complexity += 1
        
        return complexity
    
    def _analyze_dependencies(self):
        """
        üñºÔ∏è Visual - An√°lise de Depend√™ncias
        
        Representa relacionamentos entre funcionalidades cr√≠ticas
        """
        logger.info("üîó Analisando depend√™ncias entre funcionalidades cr√≠ticas...")
        
        # Analisar imports e chamadas entre funcionalidades cr√≠ticas
        for feature_id, feature in self.features.items():
            # Buscar depend√™ncias no c√≥digo
            dependencies = self._find_dependencies(feature)
            feature.dependencies = dependencies
            
            # Adicionar edges ao grafo
            for dep in dependencies:
                if dep in self.features:
                    self.dependency_graph.add_edge(dep, feature_id)
        
        # Calcular dependentes (reverse dependencies)
        for feature_id, feature in self.features.items():
            dependents = list(self.dependency_graph.predecessors(feature_id))
            feature.dependents = dependents
    
    def _find_dependencies(self, feature: CriticalFeature) -> List[str]:
        """Encontra depend√™ncias de uma funcionalidade"""
        dependencies = []
        
        try:
            with open(feature.file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            # Buscar imports e chamadas
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        # Verificar se √© funcionalidade cr√≠tica
                        for feature_id in self.features.keys():
                            if alias.name in feature_id:
                                dependencies.append(feature_id)
                
                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ""
                    for alias in node.names:
                        full_name = f"{module}.{alias.name}" if module else alias.name
                        # Verificar se √© funcionalidade cr√≠tica
                        for feature_id in self.features.keys():
                            if full_name in feature_id or alias.name in feature_id:
                                dependencies.append(feature_id)
                
                elif isinstance(node, ast.Call):
                    if isinstance(node.func, ast.Name):
                        # Verificar se √© chamada para funcionalidade cr√≠tica
                        for feature_id in self.features.keys():
                            if node.func.id in feature_id:
                                dependencies.append(feature_id)
        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao analisar depend√™ncias de {feature.name}: {e}")
        
        return dependencies
    
    def _calculate_criticality_scores(self):
        """Calcula scores de criticidade baseado em m√∫ltiplos fatores"""
        logger.info("üìä Calculando scores de criticidade...")
        
        for feature_id, feature in self.features.items():
            score = 0.0
            
            # Fator 1: Tipo de funcionalidade
            type_scores = {
                "api": 0.9,
                "service": 0.8,
                "database": 0.7,
                "security": 0.9,
                "core": 0.8,
                "function": 0.5,
                "class": 0.6,
                "module": 0.7
            }
            score += type_scores.get(feature.type, 0.5) * 0.3
            
            # Fator 2: Complexidade
            complexity_score = min(feature.complexity / 10.0, 1.0)
            score += complexity_score * 0.2
            
            # Fator 3: N√∫mero de dependentes
            dependents_score = min(len(feature.dependents) / 10.0, 1.0)
            score += dependents_score * 0.3
            
            # Fator 4: N√∫mero de depend√™ncias
            dependencies_score = min(len(feature.dependencies) / 5.0, 1.0)
            score += dependencies_score * 0.1
            
            # Fator 5: √Åreas de impacto
            impact_areas_score = len(feature.impact_areas) / 4.0
            score += impact_areas_score * 0.1
            
            # Normalizar score
            feature.criticality_score = min(score, 1.0)
            
            # Atualizar n√≠vel de risco
            if feature.criticality_score >= 0.8:
                feature.risk_level = "CRITICAL"
            elif feature.criticality_score >= 0.6:
                feature.risk_level = "HIGH"
            elif feature.criticality_score >= 0.4:
                feature.risk_level = "MEDIUM"
            else:
                feature.risk_level = "LOW"
    
    def _identify_critical_paths(self) -> List[List[str]]:
        """Identifica caminhos cr√≠ticos no grafo de depend√™ncias"""
        logger.info("üõ§Ô∏è Identificando caminhos cr√≠ticos...")
        
        critical_paths = []
        
        try:
            # Encontrar componentes fortemente conectados
            sccs = list(nx.strongly_connected_components(self.dependency_graph))
            
            # Identificar caminhos cr√≠ticos
            for scc in sccs:
                if len(scc) > 1:  # Componente com m√∫ltiplos n√≥s
                    # Calcular criticidade do componente
                    component_score = sum(
                        self.features[node_id].criticality_score 
                        for node_id in scc 
                        if node_id in self.features
                    ) / len(scc)
                    
                    if component_score >= 0.7:  # Componente cr√≠tico
                        critical_paths.append(list(scc))
            
            # Encontrar caminhos longos com alta criticidade
            for source in self.dependency_graph.nodes():
                for target in self.dependency_graph.nodes():
                    if source != target:
                        try:
                            path = nx.shortest_path(self.dependency_graph, source, target)
                            if len(path) >= 3:  # Caminho longo
                                path_score = sum(
                                    self.features[node_id].criticality_score 
                                    for node_id in path 
                                    if node_id in self.features
                                ) / len(path)
                                
                                if path_score >= 0.6:  # Caminho cr√≠tico
                                    critical_paths.append(path)
                        except nx.NetworkXNoPath:
                            continue
        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao identificar caminhos cr√≠ticos: {e}")
        
        return critical_paths
    
    def _generate_mapping_result(self, critical_paths: List[List[str]]) -> CriticalFeaturesResult:
        """Gera resultado do mapeamento"""
        # Estat√≠sticas
        total_features = len(self.features)
        critical_features = len([f for f in self.features.values() if f.criticality_score >= 0.7])
        high_risk_features = len([f for f in self.features.values() if f.risk_level in ["HIGH", "CRITICAL"]])
        
        # Por tipo
        critical_apis = len([f for f in self.features.values() if f.type == "api" and f.criticality_score >= 0.7])
        critical_services = len([f for f in self.features.values() if f.type == "service" and f.criticality_score >= 0.7])
        critical_functions = len([f for f in self.features.values() if f.type == "function" and f.criticality_score >= 0.7])
        critical_classes = len([f for f in self.features.values() if f.type == "class" and f.criticality_score >= 0.7])
        
        # Grafo de depend√™ncias
        dependency_graph = {}
        for feature_id, feature in self.features.items():
            dependency_graph[feature_id] = feature.dependencies
        
        # An√°lise de impacto
        impact_analysis = {}
        for feature_id, feature in self.features.items():
            impact_analysis[feature_id] = {
                "availability": 0.0,
                "performance": 0.0,
                "security": 0.0,
                "data_integrity": 0.0
            }
            
            for area in feature.impact_areas:
                if area in impact_analysis[feature_id]:
                    impact_analysis[feature_id][area] = feature.criticality_score
        
        # Recomenda√ß√µes
        recommendations = self._generate_recommendations()
        
        # Avalia√ß√£o de risco
        risk_assessment = {
            "LOW": len([f for f in self.features.values() if f.risk_level == "LOW"]),
            "MEDIUM": len([f for f in self.features.values() if f.risk_level == "MEDIUM"]),
            "HIGH": len([f for f in self.features.values() if f.risk_level == "HIGH"]),
            "CRITICAL": len([f for f in self.features.values() if f.risk_level == "CRITICAL"])
        }
        
        return CriticalFeaturesResult(
            total_features=total_features,
            critical_features=critical_features,
            high_risk_features=high_risk_features,
            critical_apis=critical_apis,
            critical_services=critical_services,
            critical_functions=critical_functions,
            critical_classes=critical_classes,
            dependency_graph=dependency_graph,
            impact_analysis=impact_analysis,
            recommendations=recommendations,
            risk_assessment=risk_assessment,
            critical_paths=critical_paths
        )
    
    def _generate_recommendations(self) -> List[str]:
        """Gera recomenda√ß√µes baseadas na an√°lise"""
        recommendations = []
        
        # Por criticidade
        critical_features = [f for f in self.features.values() if f.criticality_score >= 0.8]
        if critical_features:
            recommendations.append(f"üö® {len(critical_features)} funcionalidades cr√≠ticas identificadas - priorizar monitoramento")
        
        # Por complexidade
        high_complexity = [f for f in self.features.values() if f.complexity > 10]
        if high_complexity:
            recommendations.append(f"‚ö†Ô∏è {len(high_complexity)} funcionalidades com alta complexidade - considerar refatora√ß√£o")
        
        # Por depend√™ncias
        high_dependencies = [f for f in self.features.values() if len(f.dependents) > 5]
        if high_dependencies:
            recommendations.append(f"üîó {len(high_dependencies)} funcionalidades com muitas depend√™ncias - risco de cascata")
        
        # Por tipo
        apis = [f for f in self.features.values() if f.type == "api"]
        if apis:
            recommendations.append(f"üåê {len(apis)} APIs cr√≠ticas - implementar rate limiting e monitoramento")
        
        services = [f for f in self.features.values() if f.type == "service"]
        if services:
            recommendations.append(f"‚öôÔ∏è {len(services)} servi√ßos cr√≠ticos - implementar circuit breakers")
        
        return recommendations
    
    def save_mapping_results(self, result: CriticalFeaturesResult, output_file: str):
        """Salva resultados do mapeamento"""
        logger.info(f"üíæ Salvando resultados em {output_file}...")
        
        # Converter para formato serializ√°vel
        result_data = {
            "metadata": {
                "tracing_id": "CRITICAL_FEATURES_MAPPER_20250127_001",
                "timestamp": datetime.now().isoformat(),
                "version": "1.0.0",
                "project": "Omni Keywords Finder"
            },
            "summary": {
                "total_features": result.total_features,
                "critical_features": result.critical_features,
                "high_risk_features": result.high_risk_features,
                "critical_apis": result.critical_apis,
                "critical_services": result.critical_services,
                "critical_functions": result.critical_functions,
                "critical_classes": result.critical_classes
            },
            "critical_features_details": {
                feature_id: {
                    "name": feature.name,
                    "type": feature.type,
                    "file_path": feature.file_path,
                    "line_number": feature.line_number,
                    "criticality_score": feature.criticality_score,
                    "impact_areas": feature.impact_areas,
                    "dependencies": feature.dependencies,
                    "dependents": feature.dependents,
                    "complexity": feature.complexity,
                    "risk_level": feature.risk_level,
                    "description": feature.description
                }
                for feature_id, feature in self.features.items()
                if feature.criticality_score >= 0.5  # Apenas funcionalidades relevantes
            },
            "dependency_graph": result.dependency_graph,
            "impact_analysis": result.impact_analysis,
            "critical_paths": result.critical_paths,
            "recommendations": result.recommendations,
            "risk_assessment": result.risk_assessment
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ Resultados salvos em {output_file}")

def main():
    """
    üéØ Fun√ß√£o principal do mapeamento
    
    Executa mapeamento completo seguindo abordagens:
    - CoCoT: An√°lise fundamentada
    - ToT: M√∫ltiplas estrat√©gias
    - ReAct: Simula√ß√£o de impactos
    - Visual: Representa√ß√µes claras
    """
    logger.info("üöÄ Iniciando Mapeamento de Funcionalidades Cr√≠ticas")
    logger.info("üìê CoCoT: An√°lise fundamentada em boas pr√°ticas")
    logger.info("üå≤ ToT: M√∫ltiplas estrat√©gias de an√°lise")
    logger.info("‚ôªÔ∏è ReAct: Simula√ß√£o de impactos e riscos")
    logger.info("üñºÔ∏è Visual: Representa√ß√µes claras dos resultados")
    
    # Configura√ß√£o
    project_root = os.getcwd()
    output_file = "critical_features_mapping_results.json"
    
    try:
        # Inicializar mapeador
        mapper = CriticalFeaturesMapper(project_root)
        
        # Executar mapeamento
        logger.info("üîç Etapa 1: Mapeando funcionalidades cr√≠ticas...")
        result = mapper.map_critical_features()
        
        # Salvar resultados
        logger.info("üíæ Etapa 2: Salvando resultados...")
        mapper.save_mapping_results(result, output_file)
        
        # Exibir resumo
        logger.info("üéØ RESUMO DO MAPEAMENTO:")
        logger.info(f"   üìä Total de funcionalidades: {result.total_features}")
        logger.info(f"   üö® Funcionalidades cr√≠ticas: {result.critical_features}")
        logger.info(f"   ‚ö†Ô∏è Funcionalidades de alto risco: {result.high_risk_features}")
        logger.info(f"   üåê APIs cr√≠ticas: {result.critical_apis}")
        logger.info(f"   ‚öôÔ∏è Servi√ßos cr√≠ticos: {result.critical_services}")
        logger.info(f"   üîß Fun√ß√µes cr√≠ticas: {result.critical_functions}")
        logger.info(f"   üèóÔ∏è Classes cr√≠ticas: {result.critical_classes}")
        logger.info(f"   üõ§Ô∏è Caminhos cr√≠ticos: {len(result.critical_paths)}")
        logger.info(f"   üìã Recomenda√ß√µes: {len(result.recommendations)}")
        
        logger.info("‚úÖ Mapeamento de funcionalidades cr√≠ticas conclu√≠do com sucesso!")
        return 0
        
    except Exception as e:
        logger.error(f"‚ùå Erro durante mapeamento: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 