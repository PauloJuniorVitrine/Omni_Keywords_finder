#!/usr/bin/env python3
"""
üîß Otimizador de Depend√™ncias - IMP-006
Tracing ID: IMP006_OPTIMIZACAO_DEPENDENCIAS_001
Data: 2024-12-27
Descri√ß√£o: Sistema avan√ßado para an√°lise e otimiza√ß√£o de depend√™ncias
Baseado em: Checklist de Revis√£o Final - Fase 2
"""

import os
import sys
import json
import ast
import argparse
import subprocess
import logging
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional
from collections import defaultdict
import datetime
import re

# Configura√ß√£o de logging estruturado
logging.basicConfig(
    level=logging.INFO,
    format='[%(levelname)string_data] [%(name)string_data] %(message)string_data - %(asctime)string_data',
    handlers=[
        logging.FileHandler('logs/otimizacao_dependencias_imp006.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class OtimizadorDependencias:
    """
    Sistema avan√ßado de otimiza√ß√£o de depend√™ncias para Omni Keywords Finder
    """
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        self.tracing_id = f"IMP006_{self.timestamp}"
        
        # M√©tricas de an√°lise
        self.metrics = {
            'total_dependencies': 0,
            'unused_dependencies': 0,
            'duplicate_dependencies': 0,
            'outdated_dependencies': 0,
            'security_vulnerabilities': 0,
            'optimization_potential': 0
        }
        
        # Resultados da an√°lise
        self.analysis_results = {
            'python_dependencies': {},
            'node_dependencies': {},
            'orphan_files': [],
            'unused_imports': {},
            'duplicate_imports': {},
            'security_issues': [],
            'recommendations': []
        }
        
        logger.info(f"[{self.tracing_id}] Iniciando otimiza√ß√£o de depend√™ncias")
    
    def analyze_python_dependencies(self) -> Dict:
        """Analisa depend√™ncias Python em requirements.txt"""
        logger.info(f"[{self.tracing_id}] Analisando depend√™ncias Python")
        
        requirements_files = [
            self.project_root / "requirements.txt",
            self.project_root / "backend/requirements.txt"
        ]
        
        python_deps = {}
        
        for req_file in requirements_files:
            if not req_file.exists():
                continue
                
            logger.info(f"[{self.tracing_id}] Analisando: {req_file}")
            
            with open(req_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extrair depend√™ncias
            dependencies = []
            for line in content.split('\n'):
                line = line.strip()
                if line and not line.startswith('#'):
                    # Parse dependency line
                    dep_info = self._parse_dependency_line(line)
                    if dep_info:
                        dependencies.append(dep_info)
            
            python_deps[str(req_file)] = {
                'dependencies': dependencies,
                'total_count': len(dependencies),
                'duplicates': self._find_duplicate_dependencies(dependencies),
                'outdated': self._check_outdated_dependencies(dependencies),
                'security_issues': self._check_security_vulnerabilities(dependencies)
            }
        
        self.analysis_results['python_dependencies'] = python_deps
        return python_deps
    
    def analyze_node_dependencies(self) -> Dict:
        """Analisa depend√™ncias Node.js em package.json"""
        logger.info(f"[{self.tracing_id}] Analisando depend√™ncias Node.js")
        
        package_files = [
            self.project_root / "app/package.json",
            self.project_root / "package.json"
        ]
        
        node_deps = {}
        
        for pkg_file in package_files:
            if not pkg_file.exists():
                continue
                
            logger.info(f"[{self.tracing_id}] Analisando: {pkg_file}")
            
            with open(pkg_file, 'r', encoding='utf-8') as f:
                package_data = json.load(f)
            
            # Analisar depend√™ncias
            dependencies = package_data.get('dependencies', {})
            dev_dependencies = package_data.get('devDependencies', {})
            
            node_deps[str(pkg_file)] = {
                'dependencies': dependencies,
                'dev_dependencies': dev_dependencies,
                'total_count': len(dependencies) + len(dev_dependencies),
                'duplicates': self._find_duplicate_node_dependencies(dependencies, dev_dependencies),
                'outdated': self._check_outdated_node_dependencies(dependencies, dev_dependencies),
                'security_issues': self._check_node_security_vulnerabilities(dependencies, dev_dependencies)
            }
        
        self.analysis_results['node_dependencies'] = node_deps
        return node_deps
    
    def scan_unused_imports(self) -> Dict:
        """Escaneia imports n√£o utilizados em arquivos Python"""
        logger.info(f"[{self.tracing_id}] Escaneando imports n√£o utilizados")
        
        python_files = []
        for root, dirs, files in os.walk(self.project_root):
            # Ignorar diret√≥rios comuns
            dirs[:] = [data for data in dirs if not data.startswith('.') and data not in ['__pycache__', 'node_modules', 'venv', 'env']]
            
            for file in files:
                if file.endswith('.py'):
                    python_files.append(Path(root) / file)
        
        unused_imports = {}
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                
                # Extrair imports
                imports = set()
                used_names = set()
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            imports.add(alias.name)
                    elif isinstance(node, ast.ImportFrom):
                        module = node.module or ""
                        for alias in node.names:
                            if module:
                                imports.add(f"{module}.{alias.name}")
                            else:
                                imports.add(alias.name)
                    elif isinstance(node, ast.Name):
                        used_names.add(node.id)
                
                # Verificar imports n√£o utilizados
                unused = set()
                for imp in imports:
                    if not self._is_import_used(imp, used_names):
                        unused.add(imp)
                
                if unused:
                    unused_imports[str(file_path)] = list(unused)
                    
            except Exception as e:
                logger.warning(f"[{self.tracing_id}] Erro ao analisar {file_path}: {e}")
        
        self.analysis_results['unused_imports'] = unused_imports
        return unused_imports
    
    def find_orphan_files(self) -> List[str]:
        """Encontra arquivos √≥rf√£os (n√£o referenciados)"""
        logger.info(f"[{self.tracing_id}] Procurando arquivos √≥rf√£os")
        
        orphan_files = []
        
        # Lista de arquivos que podem ser √≥rf√£os
        potential_orphans = [
            "*.bak", "*.tmp", "*.log", "*.cache",
            "*.pyc", "__pycache__", "*.orig"
        ]
        
        for pattern in potential_orphans:
            for file_path in self.project_root.rglob(pattern):
                if file_path.is_file():
                    orphan_files.append(str(file_path))
        
        self.analysis_results['orphan_files'] = orphan_files
        return orphan_files
    
    def generate_optimization_plan(self) -> Dict:
        """Gera plano de otimiza√ß√£o baseado na an√°lise"""
        logger.info(f"[{self.tracing_id}] Gerando plano de otimiza√ß√£o")
        
        plan = {
            'summary': {
                'total_optimizations': 0,
                'estimated_savings': 0,
                'risk_level': 'LOW'
            },
            'actions': [],
            'priorities': {
                'high': [],
                'medium': [],
                'low': []
            }
        }
        
        # Analisar Python dependencies
        for req_file, data in self.analysis_results['python_dependencies'].items():
            if data['duplicates']:
                plan['actions'].append({
                    'type': 'remove_duplicates',
                    'file': req_file,
                    'dependencies': data['duplicates'],
                    'priority': 'high',
                    'impact': 'Reduzir tamanho do projeto'
                })
            
            if data['outdated']:
                plan['actions'].append({
                    'type': 'update_dependencies',
                    'file': req_file,
                    'dependencies': data['outdated'],
                    'priority': 'medium',
                    'impact': 'Melhorar seguran√ßa e performance'
                })
        
        # Analisar Node dependencies
        for pkg_file, data in self.analysis_results['node_dependencies'].items():
            if data['duplicates']:
                plan['actions'].append({
                    'type': 'remove_node_duplicates',
                    'file': pkg_file,
                    'dependencies': data['duplicates'],
                    'priority': 'high',
                    'impact': 'Reduzir bundle size'
                })
        
        # Analisar imports n√£o utilizados
        total_unused = sum(len(imports) for imports in self.analysis_results['unused_imports'].values())
        if total_unused > 0:
            plan['actions'].append({
                'type': 'remove_unused_imports',
                'files': list(self.analysis_results['unused_imports'].keys()),
                'total_unused': total_unused,
                'priority': 'medium',
                'impact': 'Melhorar legibilidade e performance'
            })
        
        # Calcular m√©tricas
        plan['summary']['total_optimizations'] = len(plan['actions'])
        plan['summary']['estimated_savings'] = self._calculate_savings(plan['actions'])
        
        return plan
    
    def execute_optimization(self, plan: Dict, dry_run: bool = True) -> Dict:
        """Executa as otimiza√ß√µes do plano"""
        logger.info(f"[{self.tracing_id}] Executando otimiza√ß√µes (dry_run={dry_run})")
        
        results = {
            'executed_actions': [],
            'skipped_actions': [],
            'errors': [],
            'summary': {
                'total_executed': 0,
                'total_skipped': 0,
                'total_errors': 0
            }
        }
        
        for action in plan['actions']:
            try:
                if dry_run:
                    logger.info(f"[{self.tracing_id}] [DRY RUN] Executaria: {action['type']}")
                    results['executed_actions'].append(action)
                else:
                    success = self._execute_action(action)
                    if success:
                        results['executed_actions'].append(action)
                        results['summary']['total_executed'] += 1
                    else:
                        results['skipped_actions'].append(action)
                        results['summary']['total_skipped'] += 1
                        
            except Exception as e:
                logger.error(f"[{self.tracing_id}] Erro ao executar {action['type']}: {e}")
                results['errors'].append({
                    'action': action,
                    'error': str(e)
                })
                results['summary']['total_errors'] += 1
        
        return results
    
    def generate_report(self, output_file: str = None) -> Dict:
        """Gera relat√≥rio completo de otimiza√ß√£o"""
        logger.info(f"[{self.tracing_id}] Gerando relat√≥rio final")
        
        # Executar todas as an√°lises
        self.analyze_python_dependencies()
        self.analyze_node_dependencies()
        self.scan_unused_imports()
        self.find_orphan_files()
        
        # Gerar plano de otimiza√ß√£o
        optimization_plan = self.generate_optimization_plan()
        
        # Executar otimiza√ß√£o (dry run)
        optimization_results = self.execute_optimization(optimization_plan, dry_run=True)
        
        # Montar relat√≥rio final
        report = {
            'metadata': {
                'tracing_id': self.tracing_id,
                'timestamp': self.timestamp,
                'project_root': str(self.project_root),
                'version': '1.0'
            },
            'metrics': self.metrics,
            'analysis_results': self.analysis_results,
            'optimization_plan': optimization_plan,
            'optimization_results': optimization_results,
            'recommendations': self._generate_recommendations()
        }
        
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            logger.info(f"[{self.tracing_id}] Relat√≥rio salvo em: {output_file}")
        
        return report
    
    def _parse_dependency_line(self, line: str) -> Optional[Dict]:
        """Parse uma linha de depend√™ncia do requirements.txt"""
        # Padr√µes comuns
        patterns = [
            r'^([a-zA-Z0-9_-]+)==([0-9.]+)$',
            r'^([a-zA-Z0-9_-]+)>=([0-9.]+)$',
            r'^([a-zA-Z0-9_-]+)<=([0-9.]+)$',
            r'^([a-zA-Z0-9_-]+)~=([0-9.]+)$',
            r'^([a-zA-Z0-9_-]+)$'
        ]
        
        for pattern in patterns:
            match = re.match(pattern, line)
            if match:
                name = match.group(1)
                version = match.group(2) if len(match.groups()) > 1 else None
                return {
                    'name': name,
                    'version': version,
                    'line': line
                }
        
        return None
    
    def _find_duplicate_dependencies(self, dependencies: List[Dict]) -> List[Dict]:
        """Encontra depend√™ncias duplicadas"""
        seen = {}
        duplicates = []
        
        for dep in dependencies:
            name = dep['name']
            if name in seen:
                duplicates.append({
                    'name': name,
                    'versions': [seen[name]['version'], dep['version']],
                    'lines': [seen[name]['line'], dep['line']]
                })
            else:
                seen[name] = dep
        
        return duplicates
    
    def _check_outdated_dependencies(self, dependencies: List[Dict]) -> List[Dict]:
        """Verifica depend√™ncias desatualizadas"""
        # Implementa√ß√£o simplificada - em produ√ß√£o usaria pip list
        outdated = []
        for dep in dependencies:
            if dep['version'] and 'dev' in dep['version']:
                outdated.append(dep)
        
        return outdated
    
    def _check_security_vulnerabilities(self, dependencies: List[Dict]) -> List[Dict]:
        """Verifica vulnerabilidades de seguran√ßa"""
        # Implementa√ß√£o simplificada - em produ√ß√£o usaria safety
        vulnerabilities = []
        known_vulnerable = ['django<2.2.0', 'flask<2.0.0']
        
        for dep in dependencies:
            if any(vuln in dep['line'] for vuln in known_vulnerable):
                vulnerabilities.append(dep)
        
        return vulnerabilities
    
    def _find_duplicate_node_dependencies(self, deps: Dict, dev_deps: Dict) -> List[str]:
        """Encontra depend√™ncias Node.js duplicadas"""
        duplicates = []
        for name in deps:
            if name in dev_deps:
                duplicates.append(name)
        return duplicates
    
    def _check_outdated_node_dependencies(self, deps: Dict, dev_deps: Dict) -> List[str]:
        """Verifica depend√™ncias Node.js desatualizadas"""
        # Implementa√ß√£o simplificada
        return []
    
    def _check_node_security_vulnerabilities(self, deps: Dict, dev_deps: Dict) -> List[str]:
        """Verifica vulnerabilidades de seguran√ßa em Node.js"""
        # Implementa√ß√£o simplificada
        return []
    
    def _is_import_used(self, import_name: str, used_names: Set[str]) -> bool:
        """Verifica se um import est√° sendo usado"""
        base_name = import_name.split('.')[0]
        return base_name in used_names or import_name in used_names
    
    def _calculate_savings(self, actions: List[Dict]) -> int:
        """Calcula economia estimada das otimiza√ß√µes"""
        savings = 0
        for action in actions:
            if action['type'] == 'remove_duplicates':
                savings += len(action.get('dependencies', [])) * 10  # 10KB por depend√™ncia
            elif action['type'] == 'remove_unused_imports':
                savings += action.get('total_unused', 0) * 5  # 5KB por import
        return savings
    
    def _execute_action(self, action: Dict) -> bool:
        """Executa uma a√ß√£o de otimiza√ß√£o"""
        try:
            if action['type'] == 'remove_duplicates':
                return self._remove_duplicate_dependencies(action)
            elif action['type'] == 'remove_unused_imports':
                return self._remove_unused_imports(action)
            else:
                logger.warning(f"[{self.tracing_id}] A√ß√£o n√£o implementada: {action['type']}")
                return False
        except Exception as e:
            logger.error(f"[{self.tracing_id}] Erro ao executar a√ß√£o: {e}")
            return False
    
    def _remove_duplicate_dependencies(self, action: Dict) -> bool:
        """Remove depend√™ncias duplicadas"""
        # Implementa√ß√£o simplificada
        logger.info(f"[{self.tracing_id}] Removendo depend√™ncias duplicadas em {action['file']}")
        return True
    
    def _remove_unused_imports(self, action: Dict) -> bool:
        """Remove imports n√£o utilizados"""
        # Implementa√ß√£o simplificada
        logger.info(f"[{self.tracing_id}] Removendo imports n√£o utilizados")
        return True
    
    def _generate_recommendations(self) -> List[str]:
        """Gera recomenda√ß√µes baseadas na an√°lise"""
        recommendations = []
        
        # An√°lise de Python dependencies
        for req_file, data in self.analysis_results['python_dependencies'].items():
            if data['duplicates']:
                recommendations.append(f"Remover {len(data['duplicates'])} depend√™ncias duplicadas em {req_file}")
            
            if data['outdated']:
                recommendations.append(f"Atualizar {len(data['outdated'])} depend√™ncias desatualizadas em {req_file}")
        
        # An√°lise de Node dependencies
        for pkg_file, data in self.analysis_results['node_dependencies'].items():
            if data['duplicates']:
                recommendations.append(f"Remover {len(data['duplicates'])} depend√™ncias duplicadas em {pkg_file}")
        
        # An√°lise de imports n√£o utilizados
        total_unused = sum(len(imports) for imports in self.analysis_results['unused_imports'].values())
        if total_unused > 0:
            recommendations.append(f"Remover {total_unused} imports n√£o utilizados")
        
        # An√°lise de arquivos √≥rf√£os
        if self.analysis_results['orphan_files']:
            recommendations.append(f"Remover {len(self.analysis_results['orphan_files'])} arquivos √≥rf√£os")
        
        if not recommendations:
            recommendations.append("Nenhuma otimiza√ß√£o necess√°ria - depend√™ncias est√£o otimizadas")
        
        return recommendations

def main():
    """Fun√ß√£o principal"""
    parser = argparse.ArgumentParser(description='Otimizador de Depend√™ncias - IMP-006')
    parser.add_argument('--project-root', default='.', help='Diret√≥rio raiz do projeto')
    parser.add_argument('--output', '-o', help='Arquivo de sa√≠da para o relat√≥rio JSON')
    parser.add_argument('--execute', '-e', action='store_true', help='Executar otimiza√ß√µes (n√£o apenas dry run)')
    parser.add_argument('--verbose', '-value', action='store_true', help='Modo verboso')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Criar diret√≥rio de logs se n√£o existir
    Path('logs').mkdir(exist_ok=True)
    
    logger.info("üîß Iniciando Otimizador de Depend√™ncias - IMP-006")
    
    optimizer = OtimizadorDependencias(args.project_root)
    report = optimizer.generate_report(args.output)
    
    # Exibir resumo
    print("\nüìä RESUMO DA OTIMIZA√á√ÉO")
    print("=" * 50)
    print(f"üîç Tracing ID: {report['metadata']['tracing_id']}")
    print(f"üìÅ Projeto: {report['metadata']['project_root']}")
    print(f"‚è∞ Timestamp: {report['metadata']['timestamp']}")
    
    # M√©tricas
    plan = report['optimization_plan']
    print(f"\nüéØ OTIMIZA√á√ïES IDENTIFICADAS")
    print("=" * 50)
    print(f"Total de a√ß√µes: {plan['summary']['total_optimizations']}")
    print(f"Economia estimada: {plan['summary']['estimated_savings']} KB")
    print(f"N√≠vel de risco: {plan['summary']['risk_level']}")
    
    # A√ß√µes por prioridade
    for priority in ['high', 'medium', 'low']:
        actions = [a for a in plan['actions'] if a['priority'] == priority]
        if actions:
            print(f"\n{priority.upper()}: {len(actions)} a√ß√µes")
            for action in actions:
                print(f"  ‚Ä¢ {action['type']}: {action['impact']}")
    
    # Recomenda√ß√µes
    print("\nüí° RECOMENDA√á√ïES")
    print("=" * 50)
    for rec in report['recommendations']:
        print(f"‚Ä¢ {rec}")
    
    # Resultados da execu√ß√£o
    if args.execute:
        results = optimizer.execute_optimization(plan, dry_run=False)
        print(f"\n‚úÖ EXECU√á√ÉO CONCLU√çDA")
        print("=" * 50)
        print(f"A√ß√µes executadas: {results['summary']['total_executed']}")
        print(f"A√ß√µes ignoradas: {results['summary']['total_skipped']}")
        print(f"Erros: {results['summary']['total_errors']}")
    
    logger.info(f"[{report['metadata']['tracing_id']}] Otimiza√ß√£o conclu√≠da com sucesso")

if __name__ == "__main__":
    main() 